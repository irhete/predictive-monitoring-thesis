{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset_confs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/hpchome/etais/hpc_irheta/.conda/envs/bpm3/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from DatasetManager import DatasetManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_stats = []\n",
    "datasets = [\"bpic2011_f%s\"%formula for formula in range(1,5)] + [\"bpic2015_%s_f2\"%(municipality) for municipality in range(1,6)] + [\"production\",\n",
    "                                                                                                                                    \"insurance_activity\", \"insurance_followup\",\n",
    "                                                                                                                                    \"sepsis_cases_1\", \"sepsis_cases_2\", \"sepsis_cases_4\",\n",
    "                                                                                                                                    \"bpic2012_accepted\", \"bpic2012_declined\", \"bpic2012_cancelled\",\n",
    "                                                                                                                                    \"bpic2017_accepted\", \"bpic2017_refused\", \"bpic2017_cancelled\",\n",
    "                                                                                                                                    \"traffic_fines_1\", \"hospital_billing_2\", \"hospital_billing_3\"]\n",
    "datasets = [\"unemployment\"]\n",
    "print(\"\\\\toprule  &  & min  & med  & max  & trunc  & \\\\# variants & pos class  & \\\\# event & \\\\# static  & \\\\# dynamic  & \\\\# static  & \\\\# dynamic \\\\\\\\ \")\n",
    "print(\" dataset & \\\\# traces &  length &  length &  length &  length & (after trunc) & ratio & classes &  attr-s & attr-s &  cat levels & cat levels\\\\\\\\ \\\\midrule\")\n",
    "for dataset_name in datasets:\n",
    "    dataset_manager = DatasetManager(dataset_name)\n",
    "    \n",
    "    case_id_col = dataset_confs.case_id_col[dataset_name]\n",
    "    activity_col = dataset_confs.activity_col[dataset_name]\n",
    "    timestamp_col = dataset_confs.timestamp_col[dataset_name]\n",
    "    label_col = dataset_confs.label_col[dataset_name]\n",
    "    pos_label = dataset_confs.pos_label[dataset_name]\n",
    "\n",
    "    dynamic_cat_cols = dataset_confs.dynamic_cat_cols[dataset_name]\n",
    "    static_cat_cols = dataset_confs.static_cat_cols[dataset_name]\n",
    "    dynamic_num_cols = dataset_confs.dynamic_num_cols[dataset_name]\n",
    "    static_num_cols = dataset_confs.static_num_cols[dataset_name]\n",
    "\n",
    "    data_filepath = os.path.join(home_dir, dataset_confs.filename[dataset_name])\n",
    "\n",
    "    # specify data types\n",
    "    dtypes = {col:\"object\" for col in dynamic_cat_cols+static_cat_cols+[case_id_col, label_col, timestamp_col]}\n",
    "    for col in dynamic_num_cols + static_num_cols:\n",
    "        dtypes[col] = \"float\"\n",
    "            \n",
    "    data = pd.read_csv(data_filepath, sep=\";\", dtype=dtypes)\n",
    "    sizes = data.groupby(case_id_col).size()\n",
    "\n",
    "    class_freqs = data.groupby(case_id_col).first()[label_col].value_counts()\n",
    "    \n",
    "    if \"traffic_fines\" in dataset_name:\n",
    "        max_prefix_length = 10\n",
    "    elif \"bpic2017\" in dataset_name:\n",
    "        max_prefix_length = min(20, dataset_manager.get_pos_case_length_quantile(data, 0.90))\n",
    "    else:\n",
    "        max_prefix_length = min(40, dataset_manager.get_pos_case_length_quantile(data, 0.90))\n",
    "    \n",
    "    n_trace_variants = len(data.sort_values(timestamp_col, kind=\"mergesort\").groupby(case_id_col).head(max_prefix_length).groupby(case_id_col)[activity_col].apply(lambda x: \"__\".join(list(x))).unique())\n",
    "    \n",
    "    n_static_cat_levels = 0\n",
    "    n_dynamic_cat_levels = 0\n",
    "    for col in dynamic_cat_cols:\n",
    "        n_dynamic_cat_levels += len(data[col].unique())\n",
    "    for col in static_cat_cols:\n",
    "        n_static_cat_levels += len(data[col].unique())\n",
    "    \n",
    "    dataset_name = dataset_name.replace(\"_\", \"\\\\_\").replace(\"bpic2011\\_f\", \"bpic2011\\_\").replace(\"\\_f2\", \"\").replace(\"activity\", \"1\").replace(\"followup\", \"2\").replace(\"cases\\_\", \"\").replace(\"billing\\_\", \"\").replace(\"accepted\", \"1\").replace(\"declined\", \"2\").replace(\"refused\", \"2\").replace(\"cancelled\", \"3\").replace(\"\\_fines\\_1\", \"\").replace(\"sepsis\\_4\", \"sepsis\\_3\").replace(\"hospital\\_2\", \"hospital\\_1\").replace(\"hospital\\_3\", \"hospital\\_2\")\n",
    "    print(\"%s & %s & %s & %s & %s & %s & %s & %s & %s & %s & %s & %s & %s \\\\\\\\\"%(dataset_name, len(data[case_id_col].unique()), sizes.min(), sizes.quantile(0.50), sizes.max(), max_prefix_length, n_trace_variants, round(class_freqs[pos_label] / len(data[case_id_col].unique()), 2), len(data[activity_col].unique()), len(static_cat_cols) + len(static_num_cols), len(dynamic_cat_cols) + len(dynamic_num_cols),\n",
    "                                                                      n_static_cat_levels, n_dynamic_cat_levels))\n",
    "    \n",
    "    record = (dataset_name, len(data[case_id_col].unique()), sizes.min(), sizes.quantile(0.50), sizes.max(), max_prefix_length, n_trace_variants, round(class_freqs[pos_label] / len(data[case_id_col].unique()), 2), len(data[activity_col].unique()), len(static_cat_cols) + len(static_num_cols), len(dynamic_cat_cols) + len(dynamic_num_cols),\n",
    "                                                                      n_static_cat_levels, n_dynamic_cat_levels)\n",
    "    dt_stats.append(record)\n",
    "    \n",
    "print(\"\\\\bottomrule\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "for file in glob.glob(\"results_performance/*\"):\n",
    "    tmp = pd.read_csv(file, sep=\";\")\n",
    "    \n",
    "    if \"single_agg.csv\" in file:\n",
    "        tmp[\"bucket_enc\"] = \"single_agg\"\n",
    "        \n",
    "    elif \"single_laststate.csv\" in file:\n",
    "        tmp[\"bucket_enc\"] = \"single_laststate\"\n",
    "        \n",
    "    elif \"prefix_index.csv\" in file:\n",
    "        tmp[\"bucket_enc\"] = \"prefix_index_last\"\n",
    "        data = pd.concat([data, tmp], axis=0)\n",
    "        tmp[\"bucket_enc\"] = \"prefix_index_agg\"\n",
    "        \n",
    "    data = pd.concat([data, tmp], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.DataFrame()\n",
    "for file in glob.glob(\"results_performance2/*\"):\n",
    "    tmp = pd.read_csv(file, sep=\";\")\n",
    "    \n",
    "    if \"single_agg.csv\" in file:\n",
    "        tmp[\"bucket_enc\"] = \"single_agg\"\n",
    "        \n",
    "    elif \"single_laststate.csv\" in file:\n",
    "        tmp[\"bucket_enc\"] = \"single_laststate\"\n",
    "        \n",
    "    elif \"prefix_index.csv\" in file:\n",
    "        tmp[\"bucket_enc\"] = \"prefix_index_last\"\n",
    "        data2 = pd.concat([data2, tmp], axis=0)\n",
    "        tmp[\"bucket_enc\"] = \"prefix_index_agg\"\n",
    "        \n",
    "    data2 = pd.concat([data2, tmp], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data2[~pd.isnull(data2.score)]\n",
    "data1 = data2.merge(data, on=[\"dataset\", \"bucket_enc\", \"text_method_enc\", \"cls\", \"metric\"])\n",
    "data1 = data1[data1.metric==\"offline_total_avg\"]\n",
    "data1[\"offline_total_avg\"] = data1[[\"score_x\", \"score_y\"]].mean(axis=1)\n",
    "data1[\"offline_total_std\"] = data1[[\"score_x\", \"score_y\"]].std(axis=1)\n",
    "data1 = data1.drop([\"metric\", \"score_x\", \"score_y\"], axis=1)\n",
    "data1 = pd.melt(data1, id_vars=[\"dataset\", \"bucket_enc\", \"text_method_enc\", \"cls\"], value_vars=['offline_total_avg', 'offline_total_std'])\n",
    "data1.columns = [\"dataset\", \"bucket_enc\", \"text_method_enc\", \"cls\", \"metric\", \"score\"]\n",
    "data1.set_index([\"dataset\", \"bucket_enc\", \"text_method_enc\", \"cls\", \"metric\"], inplace=True)\n",
    "data.set_index([\"dataset\", \"bucket_enc\", \"text_method_enc\", \"cls\", \"metric\"], inplace=True)\n",
    "data.update(data1)\n",
    "data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>bucket_enc</th>\n",
       "      <th>text_method_enc</th>\n",
       "      <th>cls</th>\n",
       "      <th>metric</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dc</td>\n",
       "      <td>single_laststate</td>\n",
       "      <td>no_text</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>offline_total_avg</td>\n",
       "      <td>64.302090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dc</td>\n",
       "      <td>single_laststate</td>\n",
       "      <td>no_text</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>offline_total_std</td>\n",
       "      <td>0.274182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dc</td>\n",
       "      <td>single_laststate</td>\n",
       "      <td>no_text</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>online_event_avg</td>\n",
       "      <td>0.022199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dc</td>\n",
       "      <td>single_laststate</td>\n",
       "      <td>no_text</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>online_event_std</td>\n",
       "      <td>0.007037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dc</td>\n",
       "      <td>single_laststate</td>\n",
       "      <td>no_text</td>\n",
       "      <td>logit</td>\n",
       "      <td>offline_total_avg</td>\n",
       "      <td>5.506207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset        bucket_enc text_method_enc      cls             metric  \\\n",
       "0      dc  single_laststate         no_text  xgboost  offline_total_avg   \n",
       "1      dc  single_laststate         no_text  xgboost  offline_total_std   \n",
       "2      dc  single_laststate         no_text  xgboost   online_event_avg   \n",
       "3      dc  single_laststate         no_text  xgboost   online_event_std   \n",
       "4      dc  single_laststate         no_text    logit  offline_total_avg   \n",
       "\n",
       "       score  \n",
       "0  64.302090  \n",
       "1   0.274182  \n",
       "2   0.022199  \n",
       "3   0.007037  \n",
       "4   5.506207  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/hpchome/etais/hpc_irheta/.conda/envs/bpm3/lib/python3.5/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/gpfs/hpchome/etais/hpc_irheta/.conda/envs/bpm3/lib/python3.5/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "data.dataset = data.dataset.str.replace(\"dc\", \"DR\")\n",
    "data.dataset = data.dataset.str.replace(\"crm2\", \"LtC\")\n",
    "data.dataset = data.dataset.str.replace(\"github\", \"Github\")\n",
    "\n",
    "data.bucket_enc[data.text_method_enc.str.contains(\"laststate\")] = \"prefix_index_last\"\n",
    "data.bucket_enc[data.text_method_enc.str.contains(\"agg\")] = \"prefix_index_agg\"\n",
    "\n",
    "data.text_method_enc = data.text_method_enc.str.replace(\"_laststate\", \"\")\n",
    "data.text_method_enc = data.text_method_enc.str.replace(\"_agg\", \"\")\n",
    "\n",
    "data.text_method_enc = data.text_method_enc.str.replace(\"no_text\", \"no text\")\n",
    "data.text_method_enc = data.text_method_enc.str.replace(\"nb\", \"NB\")\n",
    "data.text_method_enc = data.text_method_enc.str.replace(\"pv\", \"PV\")\n",
    "data.text_method_enc = data.text_method_enc.str.replace(\"lda\", \"LDA\")\n",
    "data.text_method_enc = data.text_method_enc.str.replace(\"bong\", \"BoNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>bucket_enc</th>\n",
       "      <th>text_method_enc</th>\n",
       "      <th>cls</th>\n",
       "      <th>metric</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>LtC</td>\n",
       "      <td>prefix_index_agg</td>\n",
       "      <td>PV</td>\n",
       "      <td>logit</td>\n",
       "      <td>offline_total_std</td>\n",
       "      <td>3765.835587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>LtC</td>\n",
       "      <td>prefix_index_agg</td>\n",
       "      <td>PV</td>\n",
       "      <td>logit</td>\n",
       "      <td>online_event_avg</td>\n",
       "      <td>0.156071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>LtC</td>\n",
       "      <td>prefix_index_agg</td>\n",
       "      <td>PV</td>\n",
       "      <td>logit</td>\n",
       "      <td>online_event_std</td>\n",
       "      <td>0.083138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>LtC</td>\n",
       "      <td>prefix_index_agg</td>\n",
       "      <td>PV</td>\n",
       "      <td>logit</td>\n",
       "      <td>offline_text_model_avg</td>\n",
       "      <td>268.314868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>LtC</td>\n",
       "      <td>prefix_index_agg</td>\n",
       "      <td>PV</td>\n",
       "      <td>logit</td>\n",
       "      <td>offline_text_model_std</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset        bucket_enc text_method_enc    cls                  metric  \\\n",
       "967     LtC  prefix_index_agg              PV  logit       offline_total_std   \n",
       "968     LtC  prefix_index_agg              PV  logit        online_event_avg   \n",
       "969     LtC  prefix_index_agg              PV  logit        online_event_std   \n",
       "970     LtC  prefix_index_agg              PV  logit  offline_text_model_avg   \n",
       "971     LtC  prefix_index_agg              PV  logit  offline_text_model_std   \n",
       "\n",
       "           score  \n",
       "967  3765.835587  \n",
       "968     0.156071  \n",
       "969     0.083138  \n",
       "970   268.314868  \n",
       "971     0.000000  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = \"rf\"\n",
    "data_cls = data[data.cls==cls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_offline_times = data_cls[data_cls.metric==\"offline_total_avg\"].groupby([\"dataset\"])[\"score\"].min().round(2)\n",
    "best_online_times = data_cls[data_cls.metric==\"online_event_avg\"].groupby([\"dataset\"])[\"score\"].min().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_encs = [\"single_agg\", \"single_laststate\", \"prefix_index_agg\", \"prefix_index_last\"]\n",
    "text_methods = [\"no text\", \"BoNG\", \"NB\", \"LDA\", \"PV\"]\n",
    "datasets = [\"DR\", \"LtC\", \"Github\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\toprule\n",
      " & \\multicolumn{2}{c}{{\\bfseries DR}} & \\multicolumn{2}{c}{{\\bfseries LtC}} & \\multicolumn{2}{c}{{\\bfseries Github}} \\\\ \\cmidrule(lr){2-3} \\cmidrule(lr){4-5} \\cmidrule(lr){6-7}\n",
      "single\\_agg & offline\\_total (s) & online\\_avg (ms) & offline\\_total (s) & online\\_avg (ms) & offline\\_total (s) & online\\_avg (ms) \\\\ \\midrule\n",
      "no text & $19.83 \\pm 0.58$ & $0.21 \\pm 0.07$ & $1648.58 \\pm 82.5$ & $0.09 \\pm 0.11$ & $1043.73 \\pm 40.63$ & $\\mathbf{0.07 \\pm 0.05}$ \\\\ \n",
      "BoNG & $29.66 \\pm 0.84$ & $0.37 \\pm 0.12$ & $22761.75 \\pm 456.53$ & $0.11 \\pm 0.13$ & $2286.96 \\pm 241.26$ & $0.56 \\pm 0.34$ \\\\ \n",
      "NB & $81.03 \\pm 1.46$ & $0.23 \\pm 0.07$ & $18208.0 \\pm 0.0$ & $0.11 \\pm 0.13$ & $2456.88 \\pm 189.07$ & $0.14 \\pm 0.09$ \\\\ \n",
      "LDA & $134.16 \\pm 2.14$ & $0.22 \\pm 0.07$ & $10303.79 \\pm 482.55$ & $\\mathbf{0.05 \\pm 0.06}$ & $2325.06 \\pm 21.31$ & $0.14 \\pm 0.08$ \\\\ \n",
      "PV & $34.4 \\pm 8.0$ & $0.25 \\pm 0.27$ & $3855.07 \\pm 174.3$ & $0.11 \\pm 0.79$ & $945.45 \\pm 17.32$ & $0.21 \\pm 0.24$ \\\\ \n",
      "\\bottomrule\n",
      " & \\multicolumn{2}{c}{{\\bfseries DR}} & \\multicolumn{2}{c}{{\\bfseries LtC}} & \\multicolumn{2}{c}{{\\bfseries Github}} \\\\ \\cmidrule(lr){2-3} \\cmidrule(lr){4-5} \\cmidrule(lr){6-7}\n",
      "single\\_laststate & offline\\_total (s) & online\\_avg (ms) & offline\\_total (s) & online\\_avg (ms) & offline\\_total (s) & online\\_avg (ms) \\\\ \\midrule\n",
      "no text & $\\mathbf{14.06 \\pm 0.43}$ & $0.2 \\pm 0.06$ & $\\mathbf{950.4 \\pm 25.6}$ & $0.08 \\pm 0.1$ & $\\mathbf{251.42 \\pm 16.26}$ & $\\mathbf{0.07 \\pm 0.05}$ \\\\ \n",
      "BoNG & $38.35 \\pm 2.09$ & $0.23 \\pm 0.07$ & $3499.5 \\pm 302.86$ & $0.08 \\pm 0.1$ & $1424.13 \\pm 33.39$ & $0.53 \\pm 0.33$ \\\\ \n",
      "NB & $34.92 \\pm 1.76$ & $0.22 \\pm 0.07$ & $3779.14 \\pm 258.75$ & $\\mathbf{0.05 \\pm 0.06}$ & $1035.07 \\pm 52.62$ & $0.08 \\pm 0.05$ \\\\ \n",
      "LDA & $85.16 \\pm 5.79$ & $0.22 \\pm 0.07$ & $62506.71 \\pm 2453.04$ & $\\mathbf{0.05 \\pm 0.06}$ & $1756.59 \\pm 27.88$ & $\\mathbf{0.07 \\pm 0.05}$ \\\\ \n",
      "PV & $103.6 \\pm 12.36$ & $0.32 \\pm 0.46$ & $1554.43 \\pm 138.73$ & $0.07 \\pm 0.83$ & $792.51 \\pm 10.35$ & $0.16 \\pm 0.26$ \\\\ \n",
      "\\bottomrule\n",
      " & \\multicolumn{2}{c}{{\\bfseries DR}} & \\multicolumn{2}{c}{{\\bfseries LtC}} & \\multicolumn{2}{c}{{\\bfseries Github}} \\\\ \\cmidrule(lr){2-3} \\cmidrule(lr){4-5} \\cmidrule(lr){6-7}\n",
      "prefix\\_index\\_agg & offline\\_total (s) & online\\_avg (ms) & offline\\_total (s) & online\\_avg (ms) & offline\\_total (s) & online\\_avg (ms) \\\\ \\midrule\n",
      "no text & $25.98 \\pm 0.52$ & $0.21 \\pm 0.06$ & $2016.05 \\pm 247.85$ & $0.19 \\pm 0.06$ & $265.76 \\pm 3.44$ & $0.08 \\pm 0.05$ \\\\ \n",
      "BoNG & $71.38 \\pm 2.52$ & $0.26 \\pm 0.1$ & $12098.83 \\pm 1956.86$ & $0.22 \\pm 0.1$ & $4931.93 \\pm 15.19$ & $0.27 \\pm 0.08$ \\\\ \n",
      "NB & $135.0 \\pm 0.78$ & $0.25 \\pm 0.08$ & $8087.82 \\pm 1378.65$ & $0.19 \\pm 0.06$ & $3253.13 \\pm 9.82$ & $0.16 \\pm 0.13$ \\\\ \n",
      "LDA & $585.43 \\pm 1.69$ & $\\mathbf{0.13 \\pm 0.05}$ & - & - & $137211.56 \\pm 68.25$ & $0.15 \\pm 0.09$ \\\\ \n",
      "PV & $685.96 \\pm 25.44$ & $0.5 \\pm 4.14$ & $21406.83 \\pm 4621.16$ & $0.28 \\pm 1.49$ & $6624.45 \\pm 150.46$ & $0.18 \\pm 0.26$ \\\\ \n",
      "\\bottomrule\n",
      " & \\multicolumn{2}{c}{{\\bfseries DR}} & \\multicolumn{2}{c}{{\\bfseries LtC}} & \\multicolumn{2}{c}{{\\bfseries Github}} \\\\ \\cmidrule(lr){2-3} \\cmidrule(lr){4-5} \\cmidrule(lr){6-7}\n",
      "prefix\\_index\\_last & offline\\_total (s) & online\\_avg (ms) & offline\\_total (s) & online\\_avg (ms) & offline\\_total (s) & online\\_avg (ms) \\\\ \\midrule\n",
      "no text & $25.98 \\pm 0.52$ & $0.21 \\pm 0.06$ & $2016.05 \\pm 247.85$ & $0.19 \\pm 0.06$ & $265.76 \\pm 3.44$ & $0.08 \\pm 0.05$ \\\\ \n",
      "BoNG & $47.35 \\pm 0.64$ & $0.25 \\pm 0.11$ & $7743.85 \\pm 1267.65$ & $0.21 \\pm 0.07$ & $1558.44 \\pm 6.77$ & $0.24 \\pm 0.1$ \\\\ \n",
      "NB & $56.77 \\pm 0.6$ & $\\mathbf{0.13 \\pm 0.05}$ & $8385.81 \\pm 326.55$ & $0.2 \\pm 0.07$ & $1709.9 \\pm 69.61$ & $0.09 \\pm 0.07$ \\\\ \n",
      "LDA & $292.75 \\pm 2.71$ & $\\mathbf{0.13 \\pm 0.04}$ & - & - & $10590.26 \\pm 24.73$ & $0.08 \\pm 0.05$ \\\\ \n",
      "PV & $502.11 \\pm 69.74$ & $0.4 \\pm 5.03$ & $18544.0 \\pm 4078.02$ & $0.28 \\pm 1.37$ & $2821.29 \\pm 52.41$ & $0.17 \\pm 0.26$ \\\\ \n",
      "\\bottomrule\n"
     ]
    }
   ],
   "source": [
    "print(\"\\\\toprule\")\n",
    "for bucket_enc in bucket_encs:\n",
    "    print(\"%s \\\\\\\\ \\\\cmidrule(lr){2-3} \\\\cmidrule(lr){4-5} \\\\cmidrule(lr){6-7}\"%(\"\".join([\" & \\multicolumn{2}{c}{{\\\\bfseries %s}}\"%(dataset.replace(\"_\", \"\\\\_\")) for dataset in datasets])))\n",
    "    print(bucket_enc.replace(\"_\", \"\\\\_\") + \" & offline\\\\_total (s) & online\\\\_avg (ms)\" * len(datasets) + \" \\\\\\\\ \\midrule\")\n",
    "    for method_name in text_methods:\n",
    "        elems_to_print = [method_name.replace(\"_\", \"\\\\_\")]\n",
    "        for dataset in datasets:\n",
    "            \n",
    "            dt_sub = data_cls[(data_cls.dataset==dataset) & (data_cls.bucket_enc==bucket_enc) & (data_cls.text_method_enc==method_name)]\n",
    "            if len(dt_sub) > 0:\n",
    "                offline_mean = round(dt_sub[dt_sub.metric==\"offline_total_avg\"].score.iloc[0], 2)\n",
    "                offline_std = round(dt_sub[dt_sub.metric==\"offline_total_std\"].score.iloc[0], 2)\n",
    "                online_mean = round(dt_sub[dt_sub.metric==\"online_event_avg\"].score.iloc[0], 2)\n",
    "                online_std = round(dt_sub[dt_sub.metric==\"online_event_std\"].score.iloc[0], 2)\n",
    "                \n",
    "                if offline_mean == best_offline_times[dataset]:\n",
    "                    elems_to_print.append(\"$\\\\mathbf{%s \\\\pm %s}$\" % (offline_mean, offline_std))\n",
    "                else:\n",
    "                    elems_to_print.append(\"$%s \\\\pm %s$\" % (offline_mean, offline_std))\n",
    "\n",
    "                if online_mean == best_online_times[dataset]:\n",
    "                    elems_to_print.append(\"$\\\\mathbf{%s \\\\pm %s}$\" % (online_mean, online_std))\n",
    "                else:\n",
    "                    elems_to_print.append(\"$%s \\\\pm %s$\" % (online_mean, online_std))\n",
    "                \n",
    "            else:\n",
    "                elems_to_print.extend([\"-\", \"-\"])\n",
    "\n",
    "        print(\"%s \\\\\\\\ \"%(\" & \".join(elems_to_print)))\n",
    "    print(\"\\\\bottomrule\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/hpchome/etais/hpc_irheta/.conda/envs/bpm3/lib/python3.5/site-packages/ipykernel/__main__.py:7: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame()\n",
    "for file in glob.glob(\"results_unstructured/*\"):\n",
    "    tmp = pd.read_csv(file, sep=\";\")\n",
    "    if not(\"bong\" in file or \"pv\" in file or \"lda\" in file or \"nb\" in file):\n",
    "        tmp.rename(index=str, columns={\"method\": \"bucket_enc\"}, inplace=True)\n",
    "        tmp[\"text_method_enc\"] = \"no text\"\n",
    "    data = pd.concat([data, tmp], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"n_test_cases.pickle\", \"rb\") as fin:\n",
    "    test_cases_dict = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_cases = pd.DataFrame(test_cases_dict)\n",
    "df_test_cases = df_test_cases.stack().reset_index()\n",
    "df_test_cases.columns = [\"nr_events\", \"dataset\", \"n_cases\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(data, df_test_cases, on=[\"dataset\", \"nr_events\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dataset = data.dataset.str.replace(\"dc\", \"DR\")\n",
    "data.dataset = data.dataset.str.replace(\"crm2\", \"LtC\")\n",
    "data.dataset = data.dataset.str.replace(\"github\", \"Github\")\n",
    "\n",
    "data.bucket_enc[data.bucket_enc==\"agg\"] = \"single_agg\"\n",
    "data.bucket_enc[data.text_method_enc.str.contains(\"laststate\")] = \"prefix_index_last\"\n",
    "data.bucket_enc[data.text_method_enc.str.contains(\"agg\")] = \"prefix_index_agg\"\n",
    "\n",
    "data.text_method_enc = data.text_method_enc.str.replace(\"_laststate\", \"\")\n",
    "data.text_method_enc = data.text_method_enc.str.replace(\"_agg\", \"\")\n",
    "\n",
    "data.text_method_enc = data.text_method_enc.str.replace(\"no_text\", \"no text\")\n",
    "data.text_method_enc = data.text_method_enc.str.replace(\"nb\", \"NB\")\n",
    "data.text_method_enc = data.text_method_enc.str.replace(\"pv\", \"PV\")\n",
    "data.text_method_enc = data.text_method_enc.str.replace(\"lda\", \"LDA\")\n",
    "data.text_method_enc = data.text_method_enc.str.replace(\"bong\", \"BoNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.bucket_enc.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"method\"] = data.bucket_enc.map(str) + \" \" + data.text_method_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_prec = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_auc = data[(data.metric==\"auc\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_auc.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mean_aucs = tmp_auc.groupby([\"dataset\", \"method\", \"cls\"]).apply(lambda group: np.average(group[\"score\"], weights=group[\"n_cases\"])).reset_index()\n",
    "all_mean_aucs.columns = [\"dataset\", \"method\", \"cls\", \"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mean_aucs = all_mean_aucs.groupby([\"dataset\"])[\"score\"].max().round(round_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mean_aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_encs = [\"single_agg\", \"single_laststate\", \"prefix_index_agg\", \"prefix_index_last\"]\n",
    "text_methods = [\"no text\", \"BoNG\", \"NB\", \"LDA\", \"PV\"]\n",
    "methods = [\"%s %s\" % (bucket_enc, text_method) for bucket_enc in bucket_encs for text_method in text_methods]\n",
    "methods.append(\"prefix_index no text\")\n",
    "cls_methods = [\"rf\", \"xgboost\", \"logit\"]\n",
    "datasets = [\"DR\", \"LtC\", \"Github\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp2 = tmp_auc.groupby(\"method\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\\\toprule\")\n",
    "print(\" & \".join([\"\"] + [\"\\\\multicolumn{3}{c}{%s}\" % cls for cls in cls_methods]))\n",
    "print(\"\\\\\\\\\")\n",
    "print(\" & \".join([\"\"] + [\"%s\"%dataset.replace(\"_\", \"\\\\_\") for dataset in datasets] * len(cls_methods)))\n",
    "print(\"\\\\\\\\ \\\\midrule\")\n",
    "for method in methods:\n",
    "    elems_to_print = [method.replace(\"_\", \"\\\\_\")]\n",
    "    if method not in tmp2.groups:\n",
    "        continue\n",
    "    tmp_method = tmp2.get_group(method)\n",
    "\n",
    "    tmp_method_cls = tmp_method.groupby(\"cls\")\n",
    "    for cls in cls_methods:\n",
    "        tmp_cls = tmp_method_cls.get_group(cls)\n",
    "        tmp_method_grouped = tmp_cls.groupby(\"dataset\")\n",
    "        for dataset_name in datasets:            \n",
    "            if dataset_name not in tmp_method_grouped.groups:\n",
    "                elems_to_print.append(\"$-$ \")\n",
    "                continue\n",
    "            tmp_dataset = tmp_method_grouped.get_group(dataset_name)\n",
    "\n",
    "            mean_value = np.average(tmp_dataset[\"score\"], weights=tmp_dataset[\"n_cases\"])\n",
    "            variance = np.average((tmp_dataset[\"score\"]-mean_value)**2, weights=tmp_dataset[\"n_cases\"])\n",
    "            std_value = round(np.sqrt(variance), round_prec)\n",
    "            mean_value = round(mean_value, round_prec)\n",
    "\n",
    "            current_str = \"\"\n",
    "            if mean_value == best_mean_aucs[dataset_name]:\n",
    "                current_str = \"$\\\\mathbf{%s}$ \"%(mean_value)\n",
    "            else:\n",
    "                current_str = \"$%s$ \" % (mean_value)\n",
    "\n",
    "            elems_to_print.append(current_str)\n",
    "\n",
    "    print(\"%s \\\\\\\\\"%(\" & \".join(elems_to_print)))\n",
    "        \n",
    "print(\"\\\\bottomrule\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inter-run stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "for file in glob.glob(\"results_stability_interrun/*\"):\n",
    "    tmp = pd.read_csv(file, sep=\";\")\n",
    "    if \"rf\" in file:\n",
    "        method_name = \"rf_\"\n",
    "    else:\n",
    "        method_name = \"xgboost_\"\n",
    "    if \"rmspd5\" in file:\n",
    "        method_name += \"auc1_rmspd5\"\n",
    "    else:\n",
    "        method_name += \"auc1_rmspd0\"\n",
    "    tmp[\"stab_method\"] = method_name\n",
    "    data = pd.concat([data, tmp], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in glob.glob(\"results_stability/*single_agg*\"):\n",
    "    tmp = pd.read_csv(file, sep=\";\")\n",
    "    if \"rf\" in file:\n",
    "        tmp[\"stab_method\"] = \"rf_orig\"\n",
    "    else:\n",
    "        tmp[\"stab_method\"] = \"xgboost_orig\"\n",
    "    data = pd.concat([data, tmp], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"n_test_cases.pickle\", \"rb\") as fin:\n",
    "    test_cases_dict = pickle.load(fin)\n",
    "    \n",
    "df_test_cases = pd.DataFrame(test_cases_dict)\n",
    "df_test_cases = df_test_cases.stack().reset_index()\n",
    "df_test_cases.columns = [\"nr_events\", \"dataset\", \"n_cases\"]\n",
    "\n",
    "data = pd.merge(data, df_test_cases, on=[\"dataset\", \"nr_events\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>method</th>\n",
       "      <th>cls</th>\n",
       "      <th>nr_events</th>\n",
       "      <th>metric</th>\n",
       "      <th>score</th>\n",
       "      <th>stab_method</th>\n",
       "      <th>n_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>production</td>\n",
       "      <td>single_agg</td>\n",
       "      <td>rf_calibrated</td>\n",
       "      <td>1</td>\n",
       "      <td>auc</td>\n",
       "      <td>0.621429</td>\n",
       "      <td>rf_auc1_rmspd0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>production</td>\n",
       "      <td>single_agg</td>\n",
       "      <td>rf_calibrated</td>\n",
       "      <td>10</td>\n",
       "      <td>auc</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>rf_auc1_rmspd0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>production</td>\n",
       "      <td>single_agg</td>\n",
       "      <td>rf_calibrated</td>\n",
       "      <td>11</td>\n",
       "      <td>auc</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>rf_auc1_rmspd0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>production</td>\n",
       "      <td>single_agg</td>\n",
       "      <td>rf_calibrated</td>\n",
       "      <td>12</td>\n",
       "      <td>auc</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>rf_auc1_rmspd0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>production</td>\n",
       "      <td>single_agg</td>\n",
       "      <td>rf_calibrated</td>\n",
       "      <td>13</td>\n",
       "      <td>auc</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>rf_auc1_rmspd0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dataset      method            cls  nr_events metric     score  \\\n",
       "0  production  single_agg  rf_calibrated          1    auc  0.621429   \n",
       "1  production  single_agg  rf_calibrated         10    auc  0.944444   \n",
       "2  production  single_agg  rf_calibrated         11    auc  1.000000   \n",
       "3  production  single_agg  rf_calibrated         12    auc  1.000000   \n",
       "4  production  single_agg  rf_calibrated         13    auc  1.000000   \n",
       "\n",
       "      stab_method  n_cases  \n",
       "0  rf_auc1_rmspd0     44.0  \n",
       "1  rf_auc1_rmspd0      9.0  \n",
       "2  rf_auc1_rmspd0      7.0  \n",
       "3  rf_auc1_rmspd0      6.0  \n",
       "4  rf_auc1_rmspd0      6.0  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dataset = data.dataset.str.replace(\"insurance_activity\", \"insurance_1\")\n",
    "data.dataset = data.dataset.str.replace(\"traffic_fines_1\", \"traffic\")\n",
    "data.dataset = data.dataset.str.replace(\"insurance_followup\", \"insurance_2\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2017_accepted\", \"bpic2017_1\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2017_refused\", \"bpic2017_2\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2017_cancelled\", \"bpic2017_3\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2012_accepted\", \"bpic2012_1\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2012_declined\", \"bpic2012_2\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2012_cancelled\", \"bpic2012_3\")\n",
    "data.dataset = data.dataset.str.replace(\"sepsis_cases_1\", \"sepsis_1\")\n",
    "data.dataset = data.dataset.str.replace(\"sepsis_cases_2\", \"sepsis_2\")\n",
    "data.dataset = data.dataset.str.replace(\"sepsis_cases_4\", \"sepsis_3\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2011_f1\", \"bpic2011_1\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2011_f2\", \"bpic2011_2\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2011_f3\", \"bpic2011_3\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2011_f4\", \"bpic2011_4\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2015_1_f2\", \"bpic2015_1\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2015_2_f2\", \"bpic2015_2\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2015_3_f2\", \"bpic2015_3\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2015_4_f2\", \"bpic2015_4\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2015_5_f2\", \"bpic2015_5\")\n",
    "data.dataset = data.dataset.str.replace(\"hospital_billing_2\", \"hospital_1\")\n",
    "data.dataset = data.dataset.str.replace(\"hospital_billing_3\", \"hospital_2\")\n",
    "data.dataset = data.dataset.str.replace(\"dc\", \"DR\")\n",
    "data.dataset = data.dataset.str.replace(\"crm2\", \"LtC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"rf_orig\", \"rf_auc1_rmspd0\", \"rf_auc1_rmspd5\", \"xgboost_orig\", \"xgboost_auc1_rmspd0\", \"xgboost_auc1_rmspd5\"]\n",
    "datasets = [\"bpic2011_%s\"%formula for formula in range(1,5)] + [\"bpic2015_%s\"%(municipality) for municipality in range(1,6)] + [\"production\",\n",
    "                                                                                                                                    \"insurance_1\", \"insurance_2\",\n",
    "                                                                                                                                    \"sepsis_1\", \"sepsis_2\", \"sepsis_3\",\n",
    "                                                                                                                                    \"bpic2012_1\", \"bpic2012_2\", \"bpic2012_3\",\n",
    "                                                                                                                                    \"bpic2017_1\", \"bpic2017_2\", \"bpic2017_3\",\n",
    "                                                                                                                                    \"traffic\", \"hospital_1\", \"hospital_2\",\n",
    "                                                                                                                               \"DR\", \"github\", \"LtC\"]\n",
    "round_prec_auc = 3\n",
    "round_prec_stab = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_auc = data[(data.metric==\"auc\")].fillna(0)\n",
    "tmp_stab = data[(data.metric==\"stability\")].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mean_aucs = tmp_auc.groupby([\"dataset\", \"stab_method\"]).apply(lambda group: np.average(group[\"score\"], weights=group[\"n_cases\"])).reset_index()\n",
    "all_mean_aucs.columns = [\"dataset\", \"stab_method\", \"score\"]\n",
    "\n",
    "all_mean_stab = tmp_stab[[\"dataset\", \"stab_method\", \"score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mean_aucs = all_mean_aucs.groupby([\"dataset\"])[\"score\"].max().round(round_prec_auc)\n",
    "best_mean_stabs = all_mean_stab.groupby([\"dataset\"])[\"score\"].max().round(round_prec_stab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset\n",
       "DR             0.981\n",
       "LtC            0.630\n",
       "bpic2011_1     0.954\n",
       "bpic2011_2     0.973\n",
       "bpic2011_3     0.980\n",
       "bpic2011_4     0.887\n",
       "bpic2012_1     0.678\n",
       "bpic2012_2     0.566\n",
       "bpic2012_3     0.709\n",
       "bpic2015_1     0.859\n",
       "bpic2015_2     0.922\n",
       "bpic2015_3     0.891\n",
       "bpic2015_4     0.877\n",
       "bpic2015_5     0.881\n",
       "bpic2017_1     0.846\n",
       "bpic2017_2     0.821\n",
       "bpic2017_3     0.813\n",
       "github         0.740\n",
       "hospital_1     0.897\n",
       "hospital_2     0.758\n",
       "insurance_1    0.879\n",
       "insurance_2    0.831\n",
       "production     0.719\n",
       "sepsis_1       0.401\n",
       "sepsis_2       0.869\n",
       "sepsis_3       0.714\n",
       "traffic        0.661\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_mean_aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset\n",
       "DR             0.992\n",
       "LtC            0.995\n",
       "bpic2011_1     0.953\n",
       "bpic2011_2     0.958\n",
       "bpic2011_3     0.975\n",
       "bpic2011_4     0.996\n",
       "bpic2012_1     0.943\n",
       "bpic2012_2     0.980\n",
       "bpic2012_3     0.952\n",
       "bpic2015_1     0.943\n",
       "bpic2015_2     0.969\n",
       "bpic2015_3     0.946\n",
       "bpic2015_4     0.955\n",
       "bpic2015_5     0.948\n",
       "bpic2017_1     0.900\n",
       "bpic2017_2     0.973\n",
       "bpic2017_3     0.900\n",
       "github         0.922\n",
       "hospital_1     0.920\n",
       "hospital_2     0.987\n",
       "insurance_1    0.954\n",
       "insurance_2    0.935\n",
       "production     0.970\n",
       "sepsis_1       0.999\n",
       "sepsis_2       0.994\n",
       "sepsis_3       0.993\n",
       "traffic        0.754\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_mean_stabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_auc = tmp_auc.groupby(\"dataset\")\n",
    "tmp_stab = tmp_stab.groupby(\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\toprule\n",
      " & \\multicolumn{6}{c}{Prediction accuracy (AUC)} & \\multicolumn{6}{c}{Temporal stability}\n",
      "\\\\\n",
      "Dataset & RF & RF\\_5 & RF\\_5\\_S & XGB & XGB\\_5 & XGB\\_5\\_S  & RF & RF\\_5 & RF\\_5\\_S & XGB & XGB\\_5 & XGB\\_5\\_S \n",
      "\\\\ \\midrule\n",
      "bpic2011\\_1 & $0.937$  & $0.935$  & $0.898$  & $0.944$  & $\\mathbf{0.954}$  & $0.925$  & $0.943$  & $0.947$  & $0.944$  & $0.951$  & $\\mathbf{0.953}$  & $0.948$  \\\\\n",
      "bpic2011\\_2 & $0.972$  & $0.972$  & $\\mathbf{0.973}$  & $0.967$  & $0.964$  & $0.969$  & $0.949$  & $0.956$  & $\\mathbf{0.958}$  & $0.948$  & $0.95$  & $0.942$  \\\\\n",
      "bpic2011\\_3 & $0.979$  & $0.979$  & $0.979$  & $\\mathbf{0.98}$  & $0.979$  & $\\mathbf{0.98}$  & $0.972$  & $\\mathbf{0.975}$  & $0.965$  & $0.971$  & $0.974$  & $0.969$  \\\\\n",
      "bpic2011\\_4 & $0.883$  & $0.871$  & $\\mathbf{0.887}$  & $0.852$  & $0.865$  & $0.884$  & $0.987$  & $0.991$  & $0.987$  & $0.993$  & $\\mathbf{0.996}$  & $0.991$  \\\\\n",
      "bpic2015\\_1 & $0.834$  & $0.827$  & $0.837$  & $\\mathbf{0.859}$  & $0.793$  & $0.84$  & $0.934$  & $0.933$  & $0.934$  & $0.941$  & $\\mathbf{0.943}$  & $0.939$  \\\\\n",
      "bpic2015\\_2 & $0.895$  & $0.898$  & $0.9$  & $0.919$  & $\\mathbf{0.922}$  & $0.869$  & $0.954$  & $0.953$  & $0.954$  & $\\mathbf{0.969}$  & $0.967$  & $0.952$  \\\\\n",
      "bpic2015\\_3 & $0.887$  & $0.886$  & $\\mathbf{0.891}$  & $0.889$  & $0.889$  & $0.886$  & $0.932$  & $0.934$  & $0.932$  & $\\mathbf{0.946}$  & $0.942$  & $0.937$  \\\\\n",
      "bpic2015\\_4 & $0.865$  & $0.862$  & $\\mathbf{0.877}$  & $0.849$  & $0.86$  & $0.876$  & $0.951$  & $0.952$  & $0.949$  & $0.954$  & $0.951$  & $\\mathbf{0.955}$  \\\\\n",
      "bpic2015\\_5 & $\\mathbf{0.881}$  & $0.873$  & $0.874$  & $0.862$  & $0.87$  & $0.863$  & $0.935$  & $0.938$  & $0.937$  & $\\mathbf{0.948}$  & $\\mathbf{0.948}$  & $0.944$  \\\\\n",
      "production & $0.668$  & $0.707$  & $\\mathbf{0.719}$  & $0.674$  & $0.667$  & $0.683$  & $\\mathbf{0.97}$  & $0.954$  & $0.953$  & $0.964$  & $0.962$  & $0.946$  \\\\\n",
      "insurance\\_1 & $\\mathbf{0.879}$  & $0.877$  & $0.875$  & $0.861$  & $0.86$  & $0.87$  & $0.936$  & $0.937$  & $0.929$  & $\\mathbf{0.954}$  & $\\mathbf{0.954}$  & $0.946$  \\\\\n",
      "insurance\\_2 & $0.81$  & $0.828$  & $\\mathbf{0.831}$  & $0.786$  & $0.806$  & $0.808$  & $0.903$  & $0.896$  & $0.893$  & $\\mathbf{0.935}$  & $0.929$  & $0.905$  \\\\\n",
      "sepsis\\_1 & $0.396$  & $0.378$  & $0.388$  & $0.348$  & $0.398$  & $\\mathbf{0.401}$  & $0.984$  & $0.977$  & $0.978$  & $0.99$  & $0.992$  & $\\mathbf{0.999}$  \\\\\n",
      "sepsis\\_2 & $0.779$  & $0.781$  & $0.758$  & $0.824$  & $\\mathbf{0.869}$  & $0.842$  & $0.985$  & $0.987$  & $0.978$  & $0.993$  & $0.992$  & $\\mathbf{0.994}$  \\\\\n",
      "sepsis\\_3 & $0.688$  & $0.691$  & $\\mathbf{0.714}$  & $0.689$  & $0.675$  & $0.708$  & $0.99$  & $0.989$  & $0.992$  & $0.992$  & $0.99$  & $\\mathbf{0.993}$  \\\\\n",
      "bpic2012\\_1 & $0.668$  & $0.667$  & $0.663$  & $0.673$  & $\\mathbf{0.678}$  & $0.676$  & $0.942$  & $0.94$  & $\\mathbf{0.943}$  & $0.937$  & $0.94$  & $0.939$  \\\\\n",
      "bpic2012\\_2 & $0.561$  & $0.565$  & $0.56$  & $0.553$  & $\\mathbf{0.566}$  & $0.561$  & $0.97$  & $0.972$  & $\\mathbf{0.98}$  & $0.977$  & $0.978$  & $0.974$  \\\\\n",
      "bpic2012\\_3 & $0.706$  & $0.708$  & $\\mathbf{0.709}$  & $0.693$  & $0.683$  & $0.665$  & $0.946$  & $0.945$  & $0.945$  & $\\mathbf{0.952}$  & $0.947$  & $0.945$  \\\\\n",
      "bpic2017\\_1 & $0.834$  & $0.835$  & $0.834$  & $0.837$  & $0.843$  & $\\mathbf{0.846}$  & $0.886$  & $0.889$  & $0.892$  & $0.889$  & $0.895$  & $0.897$  \\\\\n",
      "bpic2017\\_2 & $0.805$  & $0.808$  & $0.808$  & $0.808$  & $\\mathbf{0.821}$  & $0.817$  & $0.947$  & $0.957$  & $0.957$  & $0.97$  & $0.965$  & $0.961$  \\\\\n",
      "bpic2017\\_3 & $0.799$  & $0.801$  & $0.8$  & $0.789$  & $\\mathbf{0.813}$  & $0.808$  & $0.894$  & $0.896$  & $0.89$  & $0.881$  & $0.896$  & $0.895$  \\\\\n",
      "traffic & $0.646$  & $0.65$  & $\\mathbf{0.661}$  & $0.645$  & $0.641$  & $0.634$  & $0.737$  & $0.74$  & $\\mathbf{0.754}$  & $0.73$  & $0.731$  & $0.726$  \\\\\n",
      "hospital\\_1 & $0.884$  & $-$  & $0.884$  & $0.892$  & $\\mathbf{0.897}$  & $-$  & $\\mathbf{0.92}$  & $-$  & $0.918$  & $0.918$  & $0.919$  & $-$  \\\\\n",
      "hospital\\_2 & $0.699$  & $-$  & $0.704$  & $\\mathbf{0.758}$  & $-$  & $-$  & $0.985$  & $-$  & $0.979$  & $\\mathbf{0.987}$  & $-$  & $-$  \\\\\n",
      "DR & $\\mathbf{0.981}$  & $0.978$  & $0.977$  & $0.952$  & $0.96$  & $0.963$  & $0.931$  & $0.911$  & $0.914$  & $0.947$  & $0.952$  & $\\mathbf{0.992}$  \\\\\n",
      "github & $0.724$  & $0.721$  & $0.722$  & $\\mathbf{0.74}$  & $0.734$  & $0.737$  & $0.912$  & $0.906$  & $0.906$  & $0.915$  & $0.908$  & $0.909$  \\\\\n",
      "LtC & $0.545$  & $0.564$  & $0.044$  & $\\mathbf{0.63}$  & $0.602$  & $0.599$  & $0.975$  & $0.973$  & $0.956$  & $0.991$  & $\\mathbf{0.995}$  & $0.988$  \\\\\n",
      "\\bottomrule\n"
     ]
    }
   ],
   "source": [
    "print(\"\\\\toprule\")\n",
    "print(\" & \\\\multicolumn{6}{c}{Prediction accuracy (AUC)} & \\\\multicolumn{6}{c}{Temporal stability}\")\n",
    "print(\"\\\\\\\\\")\n",
    "print(\"Dataset & RF & RF\\\\_5 & RF\\\\_5\\\\_S & XGB & XGB\\\\_5 & XGB\\\\_5\\\\_S  & RF & RF\\\\_5 & RF\\\\_5\\\\_S & XGB & XGB\\\\_5 & XGB\\\\_5\\\\_S \")\n",
    "print(\"\\\\\\\\ \\\\midrule\")\n",
    "for dataset_name in datasets:            \n",
    "    elems_to_print = [dataset_name.replace(\"_\", \"\\\\_\")]\n",
    "    if dataset_name not in tmp_auc.groups:\n",
    "        continue\n",
    "    tmp_method = tmp_auc.get_group(dataset_name)\n",
    "    tmp_method_grouped = tmp_method.groupby(\"stab_method\")\n",
    "    for method in methods:\n",
    "        if method not in tmp_method_grouped.groups:\n",
    "            elems_to_print.append(\"$-$ \")\n",
    "            continue\n",
    "        tmp_dataset = tmp_method_grouped.get_group(method)\n",
    "\n",
    "        mean_value = np.average(tmp_dataset[\"score\"], weights=tmp_dataset[\"n_cases\"])\n",
    "        mean_value = round(mean_value, round_prec_auc)\n",
    "\n",
    "        if mean_value == best_mean_aucs[dataset_name]:\n",
    "            current_str = \"$\\\\mathbf{%s}$ \"%(mean_value)\n",
    "        else:\n",
    "            current_str = \"$%s$ \" % (mean_value)\n",
    "\n",
    "        elems_to_print.append(current_str)\n",
    "        \n",
    "    tmp_method = tmp_stab.get_group(dataset_name)\n",
    "    tmp_method_grouped = tmp_method.groupby(\"stab_method\")\n",
    "    for method in methods:\n",
    "        if method not in tmp_method_grouped.groups:\n",
    "            elems_to_print.append(\"$-$ \")\n",
    "            continue\n",
    "        tmp_dataset = tmp_method_grouped.get_group(method)\n",
    "\n",
    "        mean_value = np.average(tmp_dataset[\"score\"])\n",
    "        mean_value = round(mean_value, round_prec_stab)\n",
    "\n",
    "        if mean_value == best_mean_stabs[dataset_name]:\n",
    "            current_str = \"$\\\\mathbf{%s}$ \"%(mean_value)\n",
    "        else:\n",
    "            current_str = \"$%s$ \" % (mean_value)\n",
    "\n",
    "        elems_to_print.append(current_str)\n",
    "\n",
    "    print(\"%s \\\\\\\\\"%(\" & \".join(elems_to_print)))\n",
    "        \n",
    "print(\"\\\\bottomrule\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brier scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "for file in glob.glob(\"results_stability_brier/*\"):\n",
    "    tmp = pd.read_csv(file, sep=\";\")\n",
    "    if \"calibrated\" in file:\n",
    "        tmp[\"calibrated\"] = \"cal\"\n",
    "    else:\n",
    "        tmp[\"calibrated\"] = \"uncal\"\n",
    "    if \"prefix_index_rf\" in file:\n",
    "        tmp[\"method\"] = \"RF_idx_mul\"\n",
    "    elif \"prefix_index_xgboost\" in file:\n",
    "        tmp[\"method\"] = \"XGB_idx_mul\"\n",
    "    elif \"single_index_rf\" in file:\n",
    "        tmp[\"method\"] = \"RF_idx_pad\"\n",
    "    elif \"single_index_xgboost\" in file:\n",
    "        tmp[\"method\"] = \"XGB_idx_pad\"\n",
    "    elif \"single_agg_rf\" in file:\n",
    "        tmp[\"method\"] = \"RF_agg\"\n",
    "    elif \"single_agg_xgboost\" in file:\n",
    "        tmp[\"method\"] = \"XGB_agg\"\n",
    "    elif \"lstm\" in file:\n",
    "        tmp[\"method\"] = \"LSTM\"\n",
    "    data = pd.concat([data, tmp], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"cls\"] = data[\"cls\"].str.replace(\"_calibrated\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>method</th>\n",
       "      <th>cls</th>\n",
       "      <th>nr_events</th>\n",
       "      <th>metric</th>\n",
       "      <th>score</th>\n",
       "      <th>calibrated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dc</td>\n",
       "      <td>XGB_agg</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>5</td>\n",
       "      <td>brier</td>\n",
       "      <td>0.180381</td>\n",
       "      <td>uncal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dc</td>\n",
       "      <td>XGB_agg</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>6</td>\n",
       "      <td>brier</td>\n",
       "      <td>0.075760</td>\n",
       "      <td>uncal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dc</td>\n",
       "      <td>XGB_agg</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>7</td>\n",
       "      <td>brier</td>\n",
       "      <td>0.888106</td>\n",
       "      <td>uncal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dc</td>\n",
       "      <td>XGB_agg</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>8</td>\n",
       "      <td>brier</td>\n",
       "      <td>0.887131</td>\n",
       "      <td>uncal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dc</td>\n",
       "      <td>XGB_agg</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>-1</td>\n",
       "      <td>brier</td>\n",
       "      <td>0.023363</td>\n",
       "      <td>uncal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset   method      cls  nr_events metric     score calibrated\n",
       "4      dc  XGB_agg  xgboost          5  brier  0.180381      uncal\n",
       "5      dc  XGB_agg  xgboost          6  brier  0.075760      uncal\n",
       "6      dc  XGB_agg  xgboost          7  brier  0.888106      uncal\n",
       "7      dc  XGB_agg  xgboost          8  brier  0.887131      uncal\n",
       "8      dc  XGB_agg  xgboost         -1  brier  0.023363      uncal"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dataset = data.dataset.str.replace(\"insurance_activity\", \"insurance_1\")\n",
    "data.dataset = data.dataset.str.replace(\"traffic_fines_1\", \"traffic\")\n",
    "data.dataset = data.dataset.str.replace(\"insurance_followup\", \"insurance_2\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2017_accepted\", \"bpic2017_1\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2017_refused\", \"bpic2017_2\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2017_cancelled\", \"bpic2017_3\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2012_accepted\", \"bpic2012_1\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2012_declined\", \"bpic2012_2\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2012_cancelled\", \"bpic2012_3\")\n",
    "data.dataset = data.dataset.str.replace(\"sepsis_cases_1\", \"sepsis_1\")\n",
    "data.dataset = data.dataset.str.replace(\"sepsis_cases_2\", \"sepsis_2\")\n",
    "data.dataset = data.dataset.str.replace(\"sepsis_cases_4\", \"sepsis_3\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2011_f1\", \"bpic2011_1\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2011_f2\", \"bpic2011_2\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2011_f3\", \"bpic2011_3\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2011_f4\", \"bpic2011_4\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2015_1_f2\", \"bpic2015_1\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2015_2_f2\", \"bpic2015_2\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2015_3_f2\", \"bpic2015_3\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2015_4_f2\", \"bpic2015_4\")\n",
    "data.dataset = data.dataset.str.replace(\"bpic2015_5_f2\", \"bpic2015_5\")\n",
    "data.dataset = data.dataset.str.replace(\"hospital_billing_2\", \"hospital_1\")\n",
    "data.dataset = data.dataset.str.replace(\"hospital_billing_3\", \"hospital_2\")\n",
    "data.dataset = data.dataset.str.replace(\"dc\", \"DR\")\n",
    "data.dataset = data.dataset.str.replace(\"crm2\", \"LtC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_briers = data[data.nr_events==-1].groupby([\"dataset\", \"method\", \"calibrated\"]).apply(lambda group: np.average(group[\"score\"])).reset_index()\n",
    "all_briers.columns = [\"dataset\", \"method\", \"calibrated\", \"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_briers = all_briers.groupby([\"dataset\"])[\"score\"].min().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset\n",
       "DR             0.01\n",
       "LtC            0.11\n",
       "bpic2011_1     0.11\n",
       "bpic2011_2     0.05\n",
       "bpic2011_3     0.03\n",
       "bpic2011_4     0.13\n",
       "bpic2012_1     0.21\n",
       "bpic2012_2     0.15\n",
       "bpic2012_3     0.16\n",
       "bpic2015_1     0.09\n",
       "bpic2015_2     0.05\n",
       "bpic2015_3     0.07\n",
       "bpic2015_4     0.06\n",
       "bpic2015_5     0.08\n",
       "bpic2017_1     0.12\n",
       "bpic2017_2     0.07\n",
       "bpic2017_3     0.15\n",
       "github         0.20\n",
       "hospital_1     0.03\n",
       "hospital_2     0.04\n",
       "insurance_1    0.09\n",
       "insurance_2    0.20\n",
       "production     0.22\n",
       "sepsis_1       0.10\n",
       "sepsis_2       0.06\n",
       "sepsis_3       0.14\n",
       "traffic        0.18\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_briers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"RF_agg\", \"XGB_agg\", \"RF_idx_mul\", \"XGB_idx_mul\", \"RF_idx_pad\", \"XGB_idx_pad\", \"LSTM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"bpic2011_%s\"%formula for formula in range(1,5)] + [\"bpic2015_%s\"%(municipality) for municipality in range(1,6)] + [\"production\",\n",
    "                                                                                                                                    \"insurance_1\", \"insurance_2\",\n",
    "                                                                                                                                    \"sepsis_1\", \"sepsis_2\", \"sepsis_3\",\n",
    "                                                                                                                                    \"bpic2012_1\", \"bpic2012_2\", \"bpic2012_3\",\n",
    "                                                                                                                                    \"bpic2017_1\", \"bpic2017_2\", \"bpic2017_3\",\n",
    "                                                                                                                                    \"traffic\", \"hospital_1\", \"hospital_2\",\n",
    "                                                                                                                               \"DR\", \"github\", \"LtC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = data[data.nr_events==-1].groupby(\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DR': Int64Index([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], dtype='int64'),\n",
       " 'LtC': Int64Index([20, 33, 33, 20, 33, 20, 20, 20, 20, 20, 20, 33, 33, 33], dtype='int64'),\n",
       " 'bpic2011_1': Int64Index([36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36], dtype='int64'),\n",
       " 'bpic2011_2': Int64Index([40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40], dtype='int64'),\n",
       " 'bpic2011_3': Int64Index([31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31], dtype='int64'),\n",
       " 'bpic2011_4': Int64Index([40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40], dtype='int64'),\n",
       " 'bpic2012_1': Int64Index([40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40], dtype='int64'),\n",
       " 'bpic2012_2': Int64Index([40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40], dtype='int64'),\n",
       " 'bpic2012_3': Int64Index([40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40], dtype='int64'),\n",
       " 'bpic2015_1': Int64Index([40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40], dtype='int64'),\n",
       " 'bpic2015_2': Int64Index([40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40], dtype='int64'),\n",
       " 'bpic2015_3': Int64Index([40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40], dtype='int64'),\n",
       " 'bpic2015_4': Int64Index([40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40], dtype='int64'),\n",
       " 'bpic2015_5': Int64Index([40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40], dtype='int64'),\n",
       " 'bpic2017_1': Int64Index([20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], dtype='int64'),\n",
       " 'bpic2017_2': Int64Index([20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], dtype='int64'),\n",
       " 'bpic2017_3': Int64Index([20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], dtype='int64'),\n",
       " 'github': Int64Index([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype='int64'),\n",
       " 'hospital_1': Int64Index([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], dtype='int64'),\n",
       " 'hospital_2': Int64Index([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], dtype='int64'),\n",
       " 'insurance_1': Int64Index([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], dtype='int64'),\n",
       " 'insurance_2': Int64Index([13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13], dtype='int64'),\n",
       " 'production': Int64Index([17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17], dtype='int64'),\n",
       " 'sepsis_1': Int64Index([30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30], dtype='int64'),\n",
       " 'sepsis_2': Int64Index([13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13], dtype='int64'),\n",
       " 'sepsis_3': Int64Index([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32], dtype='int64'),\n",
       " 'traffic': Int64Index([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], dtype='int64')}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\toprule\n",
      " & \\multicolumn{2}{c}{RF\\_agg} & \\multicolumn{2}{c}{XGB\\_agg} & \\multicolumn{2}{c}{RF\\_idx\\_mul} & \\multicolumn{2}{c}{XGB\\_idx\\_mul} & \\multicolumn{2}{c}{RF\\_idx\\_pad} & \\multicolumn{2}{c}{XGB\\_idx\\_pad} & \\multicolumn{2}{c}{LSTM}\n",
      "\\\\\n",
      " & uncal & cal & uncal & cal & uncal & cal & uncal & cal & uncal & cal & uncal & cal & uncal & cal\n",
      "\\\\ \\midrule\n",
      "bpic2011\\_1 & $\\mathbf{0.11}$ & $\\mathbf{0.11}$ & $0.13$ & $\\mathbf{0.11}$ & $\\mathbf{0.11}$ & $0.12$ & $0.13$ & $0.15$ & $0.13$ & $0.15$ & $0.15$ & $0.13$ & $0.14$ & $0.16$ \\\\\n",
      "bpic2011\\_2 & $\\mathbf{0.05}$ & $\\mathbf{0.05}$ & $\\mathbf{0.05}$ & $0.06$ & $0.12$ & $0.13$ & $0.2$ & $0.2$ & $0.12$ & $0.13$ & $0.13$ & $0.16$ & $0.14$ & $0.13$ \\\\\n",
      "bpic2011\\_3 & $0.04$ & $0.04$ & $0.12$ & $\\mathbf{0.03}$ & $0.06$ & $0.07$ & $0.08$ & $0.07$ & $0.06$ & $0.07$ & $0.06$ & $0.06$ & $0.13$ & $0.14$ \\\\\n",
      "bpic2011\\_4 & $\\mathbf{0.13}$ & $0.14$ & $0.18$ & $0.16$ & $0.16$ & $0.15$ & $0.17$ & $0.16$ & $0.16$ & $0.15$ & $0.21$ & $0.16$ & $0.16$ & $0.16$ \\\\\n",
      "bpic2015\\_1 & $\\mathbf{0.09}$ & $0.1$ & $\\mathbf{0.09}$ & $0.1$ & $0.15$ & $0.16$ & $0.15$ & $0.15$ & $0.14$ & $0.15$ & $0.19$ & $0.13$ & $0.12$ & $0.13$ \\\\\n",
      "bpic2015\\_2 & $0.06$ & $0.06$ & $\\mathbf{0.05}$ & $\\mathbf{0.05}$ & $0.09$ & $0.1$ & $0.12$ & $0.11$ & $0.08$ & $0.08$ & $0.09$ & $0.09$ & $0.14$ & $0.13$ \\\\\n",
      "bpic2015\\_3 & $\\mathbf{0.07}$ & $\\mathbf{0.07}$ & $0.08$ & $0.08$ & $0.09$ & $0.1$ & $0.1$ & $0.12$ & $0.08$ & $0.1$ & $0.09$ & $0.12$ & $0.09$ & $0.09$ \\\\\n",
      "bpic2015\\_4 & $0.07$ & $0.07$ & $0.07$ & $0.07$ & $0.1$ & $0.09$ & $0.08$ & $0.08$ & $0.1$ & $0.08$ & $0.1$ & $0.1$ & $\\mathbf{0.06}$ & $\\mathbf{0.06}$ \\\\\n",
      "bpic2015\\_5 & $\\mathbf{0.08}$ & $0.09$ & $\\mathbf{0.08}$ & $0.1$ & $0.11$ & $0.12$ & $0.13$ & $0.15$ & $0.11$ & $0.14$ & $0.13$ & $0.17$ & $0.09$ & $0.1$ \\\\\n",
      "production & $0.27$ & $0.23$ & $0.35$ & $0.24$ & $0.26$ & $0.23$ & $0.28$ & $0.24$ & $0.29$ & $0.24$ & $0.29$ & $\\mathbf{0.22}$ & $0.28$ & $0.29$ \\\\\n",
      "insurance\\_1 & $\\mathbf{0.09}$ & $0.1$ & $0.12$ & $0.12$ & $0.11$ & $0.11$ & $0.12$ & $0.12$ & $0.12$ & $0.13$ & $0.14$ & $0.14$ & $0.14$ & $0.15$ \\\\\n",
      "insurance\\_2 & $0.23$ & $0.21$ & $0.29$ & $0.23$ & $0.25$ & $0.24$ & $\\mathbf{0.2}$ & $0.21$ & $0.27$ & $0.28$ & $0.34$ & $0.28$ & $0.25$ & $0.26$ \\\\\n",
      "sepsis\\_1 & $0.12$ & $0.12$ & $0.12$ & $0.11$ & $0.12$ & $\\mathbf{0.1}$ & $0.15$ & $\\mathbf{0.1}$ & $0.12$ & $0.11$ & $0.17$ & $\\mathbf{0.1}$ & $\\mathbf{0.1}$ & $\\mathbf{0.1}$ \\\\\n",
      "sepsis\\_2 & $\\mathbf{0.06}$ & $\\mathbf{0.06}$ & $\\mathbf{0.06}$ & $\\mathbf{0.06}$ & $\\mathbf{0.06}$ & $\\mathbf{0.06}$ & $\\mathbf{0.06}$ & $\\mathbf{0.06}$ & $\\mathbf{0.06}$ & $\\mathbf{0.06}$ & $\\mathbf{0.06}$ & $\\mathbf{0.06}$ & $0.07$ & $0.07$ \\\\\n",
      "sepsis\\_3 & $\\mathbf{0.14}$ & $0.15$ & $0.22$ & $0.15$ & $\\mathbf{0.14}$ & $0.15$ & $0.15$ & $0.15$ & $0.15$ & $0.15$ & $0.16$ & $0.16$ & $0.16$ & $0.16$ \\\\\n",
      "bpic2012\\_1 & $\\mathbf{0.21}$ & $0.22$ & $\\mathbf{0.21}$ & $\\mathbf{0.21}$ & $0.22$ & $0.22$ & $0.22$ & $0.22$ & $0.23$ & $0.24$ & $0.29$ & $0.24$ & $0.22$ & $0.22$ \\\\\n",
      "bpic2012\\_2 & $\\mathbf{0.15}$ & $\\mathbf{0.15}$ & $\\mathbf{0.15}$ & $\\mathbf{0.15}$ & $0.17$ & $\\mathbf{0.15}$ & $0.18$ & $\\mathbf{0.15}$ & $0.19$ & $0.16$ & $0.16$ & $0.16$ & $\\mathbf{0.15}$ & $\\mathbf{0.15}$ \\\\\n",
      "bpic2012\\_3 & $0.17$ & $\\mathbf{0.16}$ & $\\mathbf{0.16}$ & $0.17$ & $0.18$ & $0.18$ & $0.18$ & $\\mathbf{0.16}$ & $0.19$ & $0.18$ & $0.2$ & $0.19$ & $\\mathbf{0.16}$ & $\\mathbf{0.16}$ \\\\\n",
      "bpic2017\\_1 & $\\mathbf{0.12}$ & $\\mathbf{0.12}$ & $0.13$ & $0.13$ & $\\mathbf{0.12}$ & $\\mathbf{0.12}$ & $0.14$ & $0.13$ & $0.13$ & $0.13$ & $0.21$ & $0.17$ & $\\mathbf{0.12}$ & $\\mathbf{0.12}$ \\\\\n",
      "bpic2017\\_2 & $0.08$ & $0.08$ & $0.08$ & $0.08$ & $0.08$ & $0.08$ & $0.08$ & $0.08$ & $0.08$ & $0.08$ & $0.09$ & $0.09$ & $\\mathbf{0.07}$ & $0.08$ \\\\\n",
      "bpic2017\\_3 & $\\mathbf{0.15}$ & $\\mathbf{0.15}$ & $0.19$ & $0.16$ & $\\mathbf{0.15}$ & $\\mathbf{0.15}$ & $0.18$ & $0.16$ & $\\mathbf{0.15}$ & $0.16$ & $0.17$ & $0.17$ & $\\mathbf{0.15}$ & $\\mathbf{0.15}$ \\\\\n",
      "traffic & $0.19$ & $0.2$ & $0.19$ & $0.19$ & $0.2$ & $\\mathbf{0.18}$ & $0.19$ & $\\mathbf{0.18}$ & $0.2$ & $0.21$ & $0.2$ & $0.2$ & $\\mathbf{0.18}$ & $\\mathbf{0.18}$ \\\\\n",
      "hospital\\_1 & $\\mathbf{0.03}$ & $\\mathbf{0.03}$ & $\\mathbf{0.03}$ & $0.04$ & $\\mathbf{0.03}$ & $\\mathbf{0.03}$ & $\\mathbf{0.03}$ & $\\mathbf{0.03}$ & $0.04$ & $\\mathbf{0.03}$ & $0.04$ & $0.04$ & $0.04$ & $0.04$ \\\\\n",
      "hospital\\_2 & $0.05$ & $\\mathbf{0.04}$ & $\\mathbf{0.04}$ & $\\mathbf{0.04}$ & $\\mathbf{0.04}$ & $\\mathbf{0.04}$ & $\\mathbf{0.04}$ & $\\mathbf{0.04}$ & $0.05$ & $\\mathbf{0.04}$ & $\\mathbf{0.04}$ & $\\mathbf{0.04}$ & $\\mathbf{0.04}$ & $\\mathbf{0.04}$ \\\\\n",
      "DR & $0.02$ & $\\mathbf{0.01}$ & $0.02$ & $0.03$ & $0.02$ & $0.02$ & $0.02$ & $0.02$ & $0.02$ & $0.02$ & $0.02$ & $0.02$ & $0.02$ & $0.02$ \\\\\n",
      "github & $0.21$ & $\\mathbf{0.2}$ & $\\mathbf{0.2}$ & $\\mathbf{0.2}$ & $0.21$ & $\\mathbf{0.2}$ & $0.21$ & $\\mathbf{0.2}$ & $0.21$ & $\\mathbf{0.2}$ & $0.21$ & $\\mathbf{0.2}$ & $0.23$ & $0.23$ \\\\\n",
      "LtC & $0.12$ & $\\mathbf{0.11}$ & $0.12$ & $\\mathbf{0.11}$ & $\\mathbf{0.11}$ & $0.12$ & $\\mathbf{0.11}$ & $\\mathbf{0.11}$ & $\\mathbf{0.11}$ & $\\mathbf{0.11}$ & $\\mathbf{0.11}$ & $\\mathbf{0.11}$ & $0.12$ & $0.14$ \\\\\n",
      "\\bottomrule\n"
     ]
    }
   ],
   "source": [
    "print(\"\\\\toprule\")\n",
    "print(\" & \".join([\"\"] + [\"\\\\multicolumn{2}{c}{%s}\"%method.replace(\"_\", \"\\\\_\") for method in methods]))\n",
    "print(\"\\\\\\\\\")\n",
    "print(\" & \".join([\"\"] + [\"uncal & cal\"] * len(methods)))\n",
    "print(\"\\\\\\\\ \\\\midrule\")\n",
    "for dataset in datasets:\n",
    "    if dataset not in tmp.groups:\n",
    "        continue\n",
    "    elems_to_print = [dataset.replace(\"_\", \"\\\\_\")]\n",
    "    tmp_dataset = tmp.get_group(dataset)\n",
    "    tmp_method = tmp_dataset.groupby(\"method\")\n",
    "    for method in methods:\n",
    "        if method not in tmp_method.groups:\n",
    "            current_str = \"$-$ & $-$\"\n",
    "        else:\n",
    "            tmp_current = tmp_method.get_group(method)\n",
    "            uncal = np.round(tmp_current[tmp_current.calibrated==\"uncal\"].score.mean(), 2)\n",
    "            cal = np.round(tmp_current[tmp_current.calibrated==\"cal\"].score.mean(), 2)\n",
    "            if uncal == best_briers[dataset] and cal == best_briers[dataset]:\n",
    "                current_str = \"$\\mathbf{%s}$ & $\\mathbf{%s}$\" % (uncal, cal)\n",
    "            elif uncal == best_briers[dataset]:\n",
    "                current_str = \"$\\mathbf{%s}$ & $%s$\" % (uncal, cal)\n",
    "            elif cal == best_briers[dataset]:\n",
    "                current_str = \"$%s$ & $\\mathbf{%s}$\" % (uncal, cal)\n",
    "            else:\n",
    "                current_str = \"$%s$ & $%s$\" % (uncal, cal)\n",
    "            \n",
    "        elems_to_print.append(current_str)\n",
    "\n",
    "    print(\"%s \\\\\\\\\"%(\" & \".join(elems_to_print)))\n",
    "\n",
    "print(\"\\\\bottomrule\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bpm3]",
   "language": "python",
   "name": "conda-env-bpm3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
