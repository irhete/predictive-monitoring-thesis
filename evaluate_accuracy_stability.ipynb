{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_stability(group, col=\"predicted\"):\n",
    "    group[\"diff\"] = abs(group[col].shift(-1) - group[col])\n",
    "    return(group[\"diff\"].mean(skipna=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_event_nr(s):\n",
    "    m = re.match(r'.*_(\\d{1,2})$', s)\n",
    "    if m:\n",
    "        return int(m.group(1))\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_case_id(s):\n",
    "    m = re.match(r'(.*)_\\d{1,2}$', s)\n",
    "    if m:\n",
    "        return m.group(1)\n",
    "    else:\n",
    "        return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = \"results_stability\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_detailed/detailed_results_test_xgboost_crm2_single_index.csv\n",
      "results_detailed/detailed_results_test_xgboost_calibrated_crm2_single_index.csv\n"
     ]
    }
   ],
   "source": [
    "for filename in glob.glob(\"results_detailed/*test*\"):\n",
    "    print(filename)\n",
    "    dt_results = pd.read_csv(filename, sep=\";\")\n",
    "    dt_results.case_id = dt_results.case_id.astype(str)\n",
    "    \n",
    "    if \"lstm\" not in filename:\n",
    "        if \"single\" in filename:\n",
    "            dt_results[\"nr_events\"] = dt_results.case_id.apply(extract_event_nr)\n",
    "        dt_results[\"case_id\"] = dt_results.case_id.apply(extract_case_id)\n",
    "        \n",
    "    dataset_name = dt_results.dataset.iloc[0]\n",
    "    if \"params\" in dt_results.columns:\n",
    "        method_name = dt_results.params.iloc[0]\n",
    "    else:\n",
    "        method_name = dt_results.method.iloc[0]\n",
    "    cls_method = dt_results.cls.iloc[0]\n",
    "\n",
    "    with open(os.path.join(results_dir, \"results_auc_stability_%s_%s_%s.csv\" % (dataset_name, method_name, cls_method)), 'w') as csvfile:\n",
    "        spamwriter = csv.writer(csvfile, delimiter=';', quoting=csv.QUOTE_NONE)\n",
    "        spamwriter.writerow([\"dataset\", \"method\", \"cls\", \"nr_events\", \"metric\", \"score\"])\n",
    "\n",
    "        for nr_events, group in dt_results.groupby(\"nr_events\"):\n",
    "            auc = np.nan if len(set(group.actual)) < 2 else roc_auc_score(group.actual, group.predicted)\n",
    "            spamwriter.writerow([dataset_name, method_name, cls_method, nr_events, \"auc\", auc])\n",
    "\n",
    "        stab_by_case = dt_results.groupby(\"case_id\").apply(calculate_stability)\n",
    "        spamwriter.writerow([dataset_name, method_name, cls_method, -1, \"stability\", 1 - stab_by_case.mean()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"n_test_cases.pickle\", \"rb\") as fin:\n",
    "    test_cases_dict = pickle.load(fin)\n",
    "    \n",
    "df_test_cases = pd.DataFrame(test_cases_dict)\n",
    "df_test_cases = df_test_cases.stack().reset_index()\n",
    "df_test_cases.columns = [\"nr_events\", \"dataset\", \"n_cases\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = \"results_stability_smoothed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_detailed/detailed_results_test_xgboost_crm2_single_index.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/hpchome/etais/hpc_irheta/.conda/envs/bpm3/lib/python3.5/site-packages/ipykernel/__main__.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_detailed/detailed_results_test_xgboost_calibrated_crm2_single_index.csv\n"
     ]
    }
   ],
   "source": [
    "for filename in glob.glob(\"results_detailed/*test*\"):\n",
    "    print(filename)\n",
    "    \n",
    "    dt_results = pd.read_csv(filename, sep=\";\")\n",
    "    dt_results.case_id = dt_results.case_id.astype(str)\n",
    "    \n",
    "    if \"lstm\" not in filename:\n",
    "        if \"single\" in filename:\n",
    "            dt_results[\"nr_events\"] = dt_results.case_id.apply(extract_event_nr)\n",
    "        dt_results[\"case_id\"] = dt_results.case_id.apply(extract_case_id)\n",
    "\n",
    "    dataset_name = dt_results.dataset.iloc[0]\n",
    "    if \"params\" in dt_results.columns:\n",
    "        method_name = dt_results.params.iloc[0]\n",
    "        dt_results = dt_results.drop([\"params\"], axis=1)\n",
    "    else:\n",
    "        method_name = dt_results.method.iloc[0]\n",
    "        dt_results = dt_results.drop([\"method\"], axis=1)\n",
    "    cls_method = dt_results.cls\t.iloc[0]\n",
    "\n",
    "    dt_results = dt_results.drop([\"dataset\", \"cls\"], axis=1)\n",
    "    dt_results.nr_events = dt_results.nr_events.astype(int)\n",
    "\n",
    "\n",
    "    betas = [0, 0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "    smoothed_preds = dt_results[dt_results.nr_events==1]\n",
    "    for beta in betas:\n",
    "        smoothed_preds[\"smoothed_pred_%s\" % beta] = smoothed_preds[\"predicted\"]\n",
    "\n",
    "    for nr_events in range(2, dt_results.nr_events.max()+1):\n",
    "        tmp_merged = pd.merge(dt_results[dt_results.nr_events==nr_events], smoothed_preds[smoothed_preds.nr_events==(nr_events-1)].drop([\"predicted\", \"nr_events\"], axis=1), on=[\"case_id\", \"actual\"])\n",
    "        for beta in betas:\n",
    "            tmp_merged[\"smoothed_pred_%s\" % beta] = beta * tmp_merged[\"smoothed_pred_%s\" % beta] + (1-beta) * tmp_merged.predicted\n",
    "        smoothed_preds = pd.concat([smoothed_preds, tmp_merged], axis=0)\n",
    "\n",
    "    with open(os.path.join(results_dir, \"results_auc_stability_%s_%s_%s.csv\" % (dataset_name, method_name, cls_method)), 'w') as csvfile:\n",
    "        spamwriter = csv.writer(csvfile, delimiter=';', quoting=csv.QUOTE_NONE)\n",
    "        spamwriter.writerow([\"dataset\", \"method\", \"cls\", \"beta\", \"metric\", \"score\"])\n",
    "\n",
    "        for beta in betas:\n",
    "            aucs = []\n",
    "            for nr_events, group in smoothed_preds.groupby(\"nr_events\"):\n",
    "                auc = np.nan if len(set(group.actual)) < 2 else roc_auc_score(group.actual, group[\"smoothed_pred_%s\" % beta])\n",
    "                aucs.append((auc, dataset_name, nr_events))\n",
    "                \n",
    "            dt_aucs = pd.DataFrame(aucs)\n",
    "            dt_aucs.columns = [\"score\", \"dataset\", \"nr_events\"]\n",
    "            dt_aucs = pd.merge(dt_aucs, df_test_cases, on=[\"dataset\", \"nr_events\"])\n",
    "            dt_aucs[\"score\"].fillna(0, inplace=True)\n",
    "            auc = np.average(dt_aucs[\"score\"], weights=dt_aucs[\"n_cases\"])\n",
    "            spamwriter.writerow([dataset_name, method_name, cls_method, beta, \"auc\", auc])\n",
    "\n",
    "            stab_by_case = smoothed_preds.groupby(\"case_id\").apply(calculate_stability, col=\"smoothed_pred_%s\" % beta)\n",
    "            spamwriter.writerow([dataset_name, method_name, cls_method, beta, \"stability\", 1 - stab_by_case.mean()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brier scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = \"results_stability_brier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_detailed/detailed_results_test_xgboost_bpic2017_cancelled_single_index.csv\n",
      "results_detailed/detailed_results_test_xgboost_calibrated_bpic2017_cancelled_single_index.csv\n"
     ]
    }
   ],
   "source": [
    "for filename in glob.glob(\"results_detailed/*test*\"):\n",
    "    print(filename)\n",
    "    dt_results = pd.read_csv(filename, sep=\";\")\n",
    "    dt_results.case_id = dt_results.case_id.astype(str)\n",
    "    \n",
    "    if \"lstm\" not in filename:\n",
    "        if \"sepsis\" in filename:\n",
    "            dt_results.case_id = dt_results.case_id.str.replace(\"missing_caseid\", \"missing\")\n",
    "        max_underscores_in_caseid = dt_results.case_id.apply(lambda x: len(x.split(\"_\"))).max()\n",
    "        if \"single\" in filename:\n",
    "            dt_results[\"nr_events\"] = dt_results.case_id.apply(lambda x: 1 if len(x.split(\"_\")) < max_underscores_in_caseid else x.split(\"_\")[-1])\n",
    "        dt_results[\"case_id\"] = dt_results.case_id.apply(lambda x: x if len(x.split(\"_\")) < max_underscores_in_caseid else x.split(\"_\")[0])\n",
    "\n",
    "    dataset_name = dt_results.dataset.iloc[0]\n",
    "    if \"params\" in dt_results.columns:\n",
    "        method_name = dt_results.params.iloc[0]\n",
    "    else:\n",
    "        method_name = dt_results.method.iloc[0]\n",
    "    cls_method = dt_results.cls.iloc[0]\n",
    "\n",
    "    with open(os.path.join(results_dir, \"results_auc_stability_%s_%s_%s.csv\" % (dataset_name, method_name, cls_method)), 'w') as csvfile:\n",
    "        spamwriter = csv.writer(csvfile, delimiter=';', quoting=csv.QUOTE_NONE)\n",
    "        spamwriter.writerow([\"dataset\", \"method\", \"cls\", \"nr_events\", \"metric\", \"score\"])\n",
    "\n",
    "        for nr_events, group in dt_results.groupby(\"nr_events\"):\n",
    "            brier = brier_score_loss(group.actual, group.predicted)\n",
    "            spamwriter.writerow([dataset_name, method_name, cls_method, nr_events, \"brier\", brier])\n",
    "        \n",
    "        brier = brier_score_loss(dt_results.actual, dt_results.predicted)\n",
    "        spamwriter.writerow([dataset_name, method_name, cls_method, -1, \"brier\", brier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bpm3]",
   "language": "python",
   "name": "conda-env-bpm3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
