{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/hpchome/etais/hpc_irheta/.conda/envs/bpm3/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from DatasetManager import DatasetManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization with unstructured data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"dc\", \"crm2\", \"github\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbucket_methods = [\"single\"]\\ncls_encodings = [\"laststate\"]\\ntext_methods = [\"bong\"]\\ncls_methods = [\"xgboost\"]\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_encs = [\"single_index\"]\n",
    "text_method_encs = [\"bong_agg\"]\n",
    "cls_methods = [\"xgboost\", \"rf\"]\n",
    "\n",
    "\"\"\"\n",
    "bucket_methods = [\"single\"]\n",
    "cls_encodings = [\"laststate\"]\n",
    "text_methods = [\"bong\"]\n",
    "cls_methods = [\"xgboost\"]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_filename = \"experiments_optimize_params_with_unstructured_data.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    if dataset == \"dc\":\n",
    "        memory = 30000\n",
    "    else:\n",
    "        memory = 50000\n",
    "        \n",
    "    for bucket_enc in bucket_encs:\n",
    "        \n",
    "        for text_method_enc in text_method_encs:\n",
    "            \n",
    "            for cls_method in cls_methods:\n",
    "\n",
    "                if \"bong\" in text_method_enc or \"nb\" in text_method_enc:\n",
    "                    n_iter = 30\n",
    "                else:\n",
    "                    n_iter = 20\n",
    "\n",
    "                if cls_method in [\"rf\", \"logit\"]:\n",
    "                    n_iter += 10\n",
    "                else:\n",
    "                    n_iter += 50\n",
    "                \n",
    "                min_prefix_length = 1\n",
    "                if bucket_enc == \"prefix_index\":\n",
    "                    if dataset == \"github\":\n",
    "                        max_prefix_length = 7\n",
    "                    elif dataset == \"crm2\":\n",
    "                        max_prefix_length = 33\n",
    "                    else:\n",
    "                        # read the data\n",
    "                        dataset_manager = DatasetManager(dataset)\n",
    "                        data = dataset_manager.read_dataset()\n",
    "\n",
    "                        # determine min and max (truncated) prefix lengths\n",
    "                        if \"traffic_fines\" in dataset:\n",
    "                            max_prefix_length = 10\n",
    "                        elif \"bpic2017\" in dataset:\n",
    "                            max_prefix_length = min(20, dataset_manager.get_pos_case_length_quantile(data, 0.90))\n",
    "                        else:\n",
    "                            max_prefix_length = min(40, dataset_manager.get_pos_case_length_quantile(data, 0.90))\n",
    "\n",
    "                    for nr_events in range(min_prefix_length, max_prefix_length+1):\n",
    "                        cur_method_name = \"%s_%s\" % (bucket_enc, nr_events)\n",
    "\n",
    "                        output_filename = \"output_files/output_%s_%s_%s_%s.txt\"%(dataset, cur_method_name, text_method_enc, cls_method)\n",
    "                        script_filename = \"script_files/%s_%s_%s_%s.sh\" % (dataset, cur_method_name, text_method_enc, cls_method)\n",
    "\n",
    "                        with open(script_filename, \"w\") as fout:\n",
    "                            fout.write(\"#!/bin/bash\\n\")\n",
    "                            fout.write(\"#SBATCH --output=%s\\n\" % (output_filename))\n",
    "                            fout.write(\"#SBATCH --mem=%s\\n\" % memory)\n",
    "                            fout.write(\"#SBATCH --ntasks=4\\n\")\n",
    "                            fout.write(\"#SBATCH --time=7-00\\n\")\n",
    "\n",
    "                            fout.write(\"python %s %s %s %s %s %s\" % (experiments_filename,\n",
    "                                                                              dataset,\n",
    "                                                                              cur_method_name,\n",
    "                                                                              text_method_enc,\n",
    "                                                                              cls_method,\n",
    "                                                                              n_iter))\n",
    "\n",
    "                        time.sleep(1)\n",
    "                        subprocess.Popen((\"sbatch %s\" % script_filename).split())\n",
    "\n",
    "                else:\n",
    "                \n",
    "                    output_filename = \"output_files/output_%s_%s_%s_%s.txt\"%(dataset, bucket_enc, text_method_enc, cls_method)\n",
    "                    script_filename = \"script_files/%s_%s_%s_%s.sh\" % (dataset, bucket_enc, text_method_enc, cls_method)\n",
    "\n",
    "                    with open(script_filename, \"w\") as fout:\n",
    "                        fout.write(\"#!/bin/bash\\n\")\n",
    "                        fout.write(\"#SBATCH --output=%s\\n\" % (output_filename))\n",
    "                        fout.write(\"#SBATCH --mem=%s\\n\" % memory)\n",
    "                        fout.write(\"#SBATCH --ntasks=4\\n\")\n",
    "                        fout.write(\"#SBATCH --time=7-00\\n\")\n",
    "\n",
    "                        fout.write(\"python %s %s %s %s %s %s\" % (experiments_filename,\n",
    "                                                                          dataset,\n",
    "                                                                          bucket_enc,\n",
    "                                                                          text_method_enc,\n",
    "                                                                          cls_method,\n",
    "                                                                          n_iter))\n",
    "\n",
    "                    time.sleep(1)\n",
    "                    subprocess.Popen((\"sbatch %s\" % script_filename).split())\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_names = [\"lstm\"]\n",
    "cls_methods = [\"lstm\"]\n",
    "results_dir = \"val_results_lstm\"\n",
    "datasets = [\"sepsis_cases_1\", \"production\", #\"sepsis_cases_2\", \n",
    "            \"sepsis_cases_4\",\n",
    "            \"traffic_fines_1\", \"bpic2012_declined\", \"bpic2012_accepted\", #\"bpic2012_cancelled\",\n",
    "            \"bpic2017_accepted\", \"bpic2017_cancelled\", \"bpic2017_refused\", \"hospital_billing_3\"]\n",
    "datasets = [\"bpic2011_f1\", \"bpic2011_f2\", \"bpic2011_f3\", \"bpic2011_f4\", \"bpic2015_1_f2\", \"bpic2015_2_f2\",\n",
    "            \"bpic2015_3_f2\", \"bpic2015_4_f2\", \"bpic2015_5_f2\", \"hospital_billing_2\", \"insurance_activity\", \"insurance_followup\",\n",
    "           \"unemployment\"]\n",
    "datasets = [\"dc\", \"github\", \"crm2\"]\n",
    "n_iter = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in datasets:\n",
    "    if \"hospital_billing\" in dataset_name or \"bpic2017\" in dataset_name or dataset_name in [\"dc\", \"github\", \"crm2\"]:\n",
    "        memory = 50000\n",
    "    elif \"traffic\" in dataset_name or \"unemployment\" in dataset_name:\n",
    "        memory = 30000\n",
    "    elif \"bpic\" in dataset_name:\n",
    "        memory = 20000\n",
    "    else:\n",
    "        memory = 10000\n",
    "        \n",
    "    for method_name in method_names:\n",
    "        for cls_method in cls_methods:\n",
    "            params = \" \".join([dataset_name, method_name, cls_method, str(n_iter)])\n",
    "            script_file = \"script_files_lstm/run_%s_%s_%s.sh\" % (dataset_name, method_name, cls_method)\n",
    "            with open(script_file, \"w\") as fout:\n",
    "                fout.write(\"#!/bin/bash\\n\")\n",
    "                fout.write(\"#SBATCH --partition=gpu\\n\")\n",
    "                fout.write(\"#SBATCH --gres=gpu:1\\n\")\n",
    "                fout.write(\"#SBATCH --output=output_files/output_%s_%s_%s.txt\\n\" % (dataset_name, method_name,\n",
    "                                                                           cls_method))\n",
    "                fout.write(\"#SBATCH --mem=%s\\n\" % memory)\n",
    "                fout.write(\"#SBATCH --time=7-00\\n\")\n",
    "                fout.write(\"source activate cuda8_env\\n\")\n",
    "                fout.write(\"python experiments_optimize_params_lstm.py %s\" % params)\n",
    "\n",
    "            #time.sleep(1)\n",
    "            #subprocess.Popen((\"sbatch %s\" % script_file).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization for inter-run stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_names = [\"single_agg\"]\n",
    "cls_methods = [\"rf\"]\n",
    "datasets = [\"bpic2011_f1\", \"bpic2011_f2\", \"bpic2011_f3\", \"bpic2011_f4\", \"bpic2015_1_f2\", \"bpic2015_2_f2\",\n",
    "           \"bpic2015_3_f2\", \"bpic2015_4_f2\", \"bpic2015_5_f2\", \"insurance_activity\", \"insurance_followup\"]\n",
    "datasets = [\"bpic2011_f4\", \"bpic2015_1_f2\", \"bpic2015_2_f2\", \"insurance_followup\"]\n",
    "datasets = [\"hospital_billing_2\", \"hospital_billing_3\"]\n",
    "n_runs = 2\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script_files/run_hospital_billing_2_single_agg_rf_1_0.sh\n",
      "script_files/run_hospital_billing_3_single_agg_rf_1_0.sh\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in datasets:\n",
    "    if dataset_name in [\"dc\", \"crm2\", \"github\"]:\n",
    "        experiments_filename = \"experiments_optimize_params_single_multirun_unstructured.py\"\n",
    "    else:\n",
    "        experiments_filename = \"experiments_optimize_params_single_multirun.py\"\n",
    "    \n",
    "    if \"hospital_billing\" in dataset_name or \"bpic2017\" in dataset_name or dataset_name in [\"dc\", \"crm2\", \"github\"]:\n",
    "        memory = 50000\n",
    "    elif \"traffic\" in dataset_name:\n",
    "        memory = 50000\n",
    "    else:\n",
    "        memory = 20000\n",
    "        \n",
    "    for method_name in method_names:\n",
    "        for cls_method in cls_methods:\n",
    "            \n",
    "            if cls_method == \"rf\":\n",
    "                n_iter = 10\n",
    "            elif cls_method == \"xgboost\":\n",
    "                n_iter = 50\n",
    "                \n",
    "            if \"hospital\" in dataset_name or \"bpic2017\" in dataset_name or \"crm2\" in dataset_name:\n",
    "                if cls_method == \"rf\":\n",
    "                    n_iter = 8\n",
    "                elif cls_method == \"xgboost\":\n",
    "                    n_iter = 20\n",
    "            \n",
    "            for beta in [0]:\n",
    "                params_dir = \"val_results_auc1_rmspd%s\" % beta\n",
    "            \n",
    "                params = \" \".join([dataset_name, method_name, cls_method, str(n_runs), str(n_iter), str(alpha), str(beta), params_dir])\n",
    "                script_file = \"script_files/run_%s_%s_%s_%s_%s.sh\" % (dataset_name, method_name, cls_method, alpha, beta)\n",
    "                print(script_file)\n",
    "                with open(script_file, \"w\") as fout:\n",
    "                    fout.write(\"#!/bin/bash\\n\")\n",
    "                    fout.write(\"#SBATCH --output=output_files/output_%s_%s_%s_%s_%s.txt\\n\" % (dataset_name, method_name,\n",
    "                                                                               cls_method, alpha, beta))\n",
    "                    fout.write(\"#SBATCH --mem=%s\\n\" % memory)\n",
    "                    fout.write(\"#SBATCH --ntasks=4\\n\")\n",
    "                    fout.write(\"#SBATCH --time=7-00\\n\")\n",
    "\n",
    "                    fout.write(\"python %s %s\" % (experiments_filename, params))\n",
    "\n",
    "                time.sleep(1)\n",
    "                subprocess.Popen((\"sbatch %s\" % script_file).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization (regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DatasetManager import DatasetManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_names = [\"single_agg\"]\n",
    "cls_methods = [\"xgboost\"]\n",
    "datasets = [\"unemployment\"]\n",
    "\n",
    "experiments_filename = \"experiments_optimize_params.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script_files/run_unemployment_single_agg_xgboost.sh\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in datasets:\n",
    "    if \"hospital_billing\" in dataset_name or \"bpic2017\" in dataset_name or \"unemployment\" in dataset_name:\n",
    "        memory = 50000\n",
    "    elif \"traffic\" in dataset_name or \"crm2\" in dataset_name or \"github\" in dataset_name:\n",
    "        memory = 50000\n",
    "    else:\n",
    "        memory = 20000\n",
    "        \n",
    "    for cls_method in cls_methods:\n",
    "\n",
    "        if cls_method == \"rf\":\n",
    "            n_iter = 10\n",
    "        elif cls_method == \"xgboost\":\n",
    "            n_iter = 50\n",
    "        \n",
    "        for method_name in method_names:\n",
    "            min_prefix_length = 1\n",
    "            if \"prefix_index\" in method_name:\n",
    "                if dataset_name == \"github\":\n",
    "                    max_prefix_length = 7\n",
    "                elif dataset_name == \"crm2\":\n",
    "                    max_prefix_length = 33\n",
    "                else:\n",
    "                    # read the data\n",
    "                    dataset_manager = DatasetManager(dataset_name)\n",
    "                    data = dataset_manager.read_dataset()\n",
    "\n",
    "                    # determine min and max (truncated) prefix lengths\n",
    "                    if \"traffic_fines\" in dataset_name:\n",
    "                        max_prefix_length = 10\n",
    "                    elif \"bpic2017\" in dataset_name:\n",
    "                        max_prefix_length = min(20, dataset_manager.get_pos_case_length_quantile(data, 0.90))\n",
    "                    else:\n",
    "                        max_prefix_length = min(40, dataset_manager.get_pos_case_length_quantile(data, 0.90))\n",
    "\n",
    "                for nr_events in range(min_prefix_length, max_prefix_length+1):\n",
    "                    cur_method_name = \"%s_%s\" % (method_name, nr_events)\n",
    "\n",
    "                    params = \" \".join([dataset_name, cur_method_name, cls_method, str(n_iter)])\n",
    "                    script_file = \"script_files/run_%s_%s_%s.sh\" % (dataset_name, cur_method_name, cls_method)\n",
    "                    print(script_file)\n",
    "                    with open(script_file, \"w\") as fout:\n",
    "                        fout.write(\"#!/bin/bash\\n\")\n",
    "                        fout.write(\"#SBATCH --output=output_files/output_%s_%s_%s.txt\\n\" % (dataset_name, cur_method_name,\n",
    "                                                                                   cls_method))\n",
    "                        fout.write(\"#SBATCH --mem=%s\\n\" % memory)\n",
    "                        fout.write(\"#SBATCH --ntasks=4\\n\")\n",
    "                        fout.write(\"#SBATCH --time=7-00\\n\")\n",
    "\n",
    "                        fout.write(\"python %s %s\" % (experiments_filename, params))\n",
    "\n",
    "                    time.sleep(1)\n",
    "                    subprocess.Popen((\"sbatch %s\" % script_file).split())\n",
    "                    \n",
    "            else:\n",
    "                params = \" \".join([dataset_name, method_name, cls_method, str(n_iter)])\n",
    "                script_file = \"script_files/run_%s_%s_%s.sh\" % (dataset_name, method_name, cls_method)\n",
    "                print(script_file)\n",
    "                with open(script_file, \"w\") as fout:\n",
    "                    fout.write(\"#!/bin/bash\\n\")\n",
    "                    fout.write(\"#SBATCH --output=output_files/output_%s_%s_%s.txt\\n\" % (dataset_name, method_name,\n",
    "                                                                               cls_method))\n",
    "                    fout.write(\"#SBATCH --mem=%s\\n\" % memory)\n",
    "                    fout.write(\"#SBATCH --ntasks=4\\n\")\n",
    "                    fout.write(\"#SBATCH --time=7-00\\n\")\n",
    "\n",
    "                    fout.write(\"python %s %s\" % (experiments_filename, params))\n",
    "\n",
    "                time.sleep(1)\n",
    "                subprocess.Popen((\"sbatch %s\" % script_file).split())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final results (regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_names = [\"prefix_index\", \"prefix_agg\"]\n",
    "cls_methods = [\"xgboost\"]\n",
    "datasets = [\"production\", \"sepsis_cases_4\", \"traffic_fines_1\", \"bpic2012_accepted\", \"bpic2012_declined\", \"bpic2011_f4\", \"bpic2015_2_f2\", \"insurance_activity\",\n",
    "           \"bpic2017_refused\", \"hospital_billing_3\"]\n",
    "truncate = \"nottrunc\"\n",
    "\n",
    "experiments_filename = \"experiments.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script_files/run_final_production_prefix_index_xgboost_nottrunc.sh\n",
      "script_files/run_final_production_prefix_agg_xgboost_nottrunc.sh\n",
      "script_files/run_final_sepsis_cases_4_prefix_index_xgboost_nottrunc.sh\n",
      "script_files/run_final_sepsis_cases_4_prefix_agg_xgboost_nottrunc.sh\n",
      "script_files/run_final_traffic_fines_1_prefix_index_xgboost_nottrunc.sh\n",
      "script_files/run_final_traffic_fines_1_prefix_agg_xgboost_nottrunc.sh\n",
      "script_files/run_final_bpic2012_accepted_prefix_index_xgboost_nottrunc.sh\n",
      "script_files/run_final_bpic2012_accepted_prefix_agg_xgboost_nottrunc.sh\n",
      "script_files/run_final_bpic2012_declined_prefix_index_xgboost_nottrunc.sh\n",
      "script_files/run_final_bpic2012_declined_prefix_agg_xgboost_nottrunc.sh\n",
      "script_files/run_final_bpic2011_f4_prefix_index_xgboost_nottrunc.sh\n",
      "script_files/run_final_bpic2011_f4_prefix_agg_xgboost_nottrunc.sh\n",
      "script_files/run_final_bpic2015_2_f2_prefix_index_xgboost_nottrunc.sh\n",
      "script_files/run_final_bpic2015_2_f2_prefix_agg_xgboost_nottrunc.sh\n",
      "script_files/run_final_insurance_activity_prefix_index_xgboost_nottrunc.sh\n",
      "script_files/run_final_insurance_activity_prefix_agg_xgboost_nottrunc.sh\n",
      "script_files/run_final_bpic2017_refused_prefix_index_xgboost_nottrunc.sh\n",
      "script_files/run_final_bpic2017_refused_prefix_agg_xgboost_nottrunc.sh\n",
      "script_files/run_final_hospital_billing_3_prefix_index_xgboost_nottrunc.sh\n",
      "script_files/run_final_hospital_billing_3_prefix_agg_xgboost_nottrunc.sh\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in datasets:\n",
    "    if \"hospital_billing\" in dataset_name or \"bpic2017\" in dataset_name:\n",
    "        memory = 30000\n",
    "    elif \"traffic\" in dataset_name or \"crm2\" in dataset_name:\n",
    "        memory = 30000\n",
    "    else:\n",
    "        memory = 20000\n",
    "        \n",
    "    for cls_method in cls_methods:\n",
    "\n",
    "        for method_name in method_names:\n",
    "            \n",
    "            params = \" \".join([dataset_name, method_name, cls_method, truncate])\n",
    "            script_file = \"script_files/run_final_%s_%s_%s_%s.sh\" % (dataset_name, method_name, cls_method, truncate)\n",
    "            print(script_file)\n",
    "            with open(script_file, \"w\") as fout:\n",
    "                fout.write(\"#!/bin/bash\\n\")\n",
    "                fout.write(\"#SBATCH --output=output_files/output_final_%s_%s_%s_%s.txt\\n\" % (dataset_name, method_name,\n",
    "                                                                           cls_method, truncate))\n",
    "                fout.write(\"#SBATCH --mem=%s\\n\" % memory)\n",
    "                fout.write(\"#SBATCH --ntasks=4\\n\")\n",
    "                fout.write(\"#SBATCH --time=7-00\\n\")\n",
    "\n",
    "                fout.write(\"python %s %s\" % (experiments_filename, params))\n",
    "\n",
    "            time.sleep(1)\n",
    "            subprocess.Popen((\"sbatch %s\" % script_file).split())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final results (unstructured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_names = [\"single_index\"]\n",
    "text_method_encs = [\"bong_agg\"]\n",
    "datasets = [\"dc\"]\n",
    "cls_methods = [\"xgboost\"]\n",
    "\n",
    "experiments_filename = \"experiments_with_unstructured_data.py\"\n",
    "#experiments_filename = \"experiments_with_unstructured_data_fixed_params.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script_files/run_final_dc_single_index_bong_agg_xgboost.sh\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in datasets:\n",
    "    if \"github\" in dataset_name or \"crm2\" in dataset_name:\n",
    "        memory = 50000\n",
    "    else:\n",
    "        memory = 25000\n",
    "        \n",
    "    for cls_method in cls_methods:\n",
    "\n",
    "        for method_name in method_names:\n",
    "            \n",
    "            for text_method in text_method_encs:\n",
    "            \n",
    "                params = \" \".join([dataset_name, method_name, text_method, cls_method])\n",
    "                script_file = \"script_files/run_final_%s_%s_%s_%s.sh\" % (dataset_name, method_name, text_method, cls_method)\n",
    "                print(script_file)\n",
    "                with open(script_file, \"w\") as fout:\n",
    "                    fout.write(\"#!/bin/bash\\n\")\n",
    "                    fout.write(\"#SBATCH --output=output_files/output_final_%s_%s_%s_%s.txt\\n\" % (dataset_name, method_name,\n",
    "                                                                               text_method, cls_method))\n",
    "                    fout.write(\"#SBATCH --mem=%s\\n\" % memory)\n",
    "                    fout.write(\"#SBATCH --ntasks=4\\n\")\n",
    "                    fout.write(\"#SBATCH --time=7-00\\n\")\n",
    "\n",
    "                    fout.write(\"python %s %s\" % (experiments_filename, params))\n",
    "\n",
    "                time.sleep(1)\n",
    "                subprocess.Popen((\"sbatch %s\" % script_file).split())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing predictions (stability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_names = [\"single_index\"]\n",
    "cls_methods = [\"xgboost\", \"xgboost_calibrated\"]\n",
    "datasets = [\"bpic2011\", \"bpic2015\", \"insurance\", \"sepsis_cases\", \"production\", \"bpic2012_accepted\", \"bpic2012_declined\", \n",
    "           \"bpic2012_cancelled\", \"traffic_fines_1\", \"bpic2017_accepted\", \"bpic2017_refused\", \"bpic2017_cancelled\",\n",
    "           \"hospital_billing_2\", \"hospital_billing_3\"]\n",
    "datasets = [\"crm2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script_files/run_writepreds_stab_crm2_single_index_xgboost.sh\n",
      "script_files/run_writepreds_stab_crm2_single_index_xgboost_calibrated.sh\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in datasets:\n",
    "    if dataset_name in [\"dc\", \"crm2\", \"github\"]:\n",
    "        experiments_filename = \"experiments_write_predictions_stability_unstructured.py\"\n",
    "    else:\n",
    "        experiments_filename = \"experiments_write_predictions_stability.py\"\n",
    "    \n",
    "    if dataset_name in [\"crm2\", \"github\"]:\n",
    "        memory = 50000\n",
    "    elif \"hospital_billing\" in dataset_name or \"bpic2017\" in dataset_name or dataset_name == \"dc\":\n",
    "        memory = 50000\n",
    "    elif \"traffic\" in dataset_name or \"crm2\" in dataset_name:\n",
    "        memory = 20000\n",
    "    else:\n",
    "        memory = 10000\n",
    "        \n",
    "    for cls_method in cls_methods:\n",
    "\n",
    "        for method_name in method_names:\n",
    "            \n",
    "            params = \" \".join([dataset_name, method_name, cls_method])\n",
    "            script_file = \"script_files/run_writepreds_stab_%s_%s_%s.sh\" % (dataset_name, method_name, cls_method)\n",
    "            print(script_file)\n",
    "            with open(script_file, \"w\") as fout:\n",
    "                fout.write(\"#!/bin/bash\\n\")\n",
    "                fout.write(\"#SBATCH --output=output_files/output_writepreds_stab_%s_%s_%s.txt\\n\" % (dataset_name, method_name,\n",
    "                                                                           cls_method))\n",
    "                fout.write(\"#SBATCH --mem=%s\\n\" % memory)\n",
    "                fout.write(\"#SBATCH --ntasks=4\\n\")\n",
    "                fout.write(\"#SBATCH --time=7-00\\n\")\n",
    "\n",
    "                fout.write(\"python %s %s\" % (experiments_filename, params))\n",
    "\n",
    "            time.sleep(1)\n",
    "            subprocess.Popen((\"sbatch %s\" % script_file).split())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing predictions (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_names = [\"lstm\"]\n",
    "cls_methods = [\"lstm\", \"lstm_calibrated\"]\n",
    "datasets = [\"sepsis_cases_4\",\n",
    "            \"traffic_fines_1\", \"bpic2012_declined\", \"bpic2012_accepted\",\n",
    "            \"bpic2017_cancelled\", \"bpic2017_refused\", \"hospital_billing_3\",\n",
    "            \"bpic2011_f1\", \"bpic2011_f2\", \"bpic2011_f3\", \"bpic2011_f4\", \"bpic2015_1_f2\", \"bpic2015_2_f2\",\n",
    "            \"bpic2015_3_f2\", \"bpic2015_4_f2\", \"bpic2015_5_f2\", \"hospital_billing_2\", \"insurance_activity\", \n",
    "            \"insurance_followup\"]\n",
    "datasets = [\"bpic2017_accepted\", \"bpic2017_refused\", \"hospital_billing_2\", \"hospital_billing_3\"]\n",
    "datasets = [\"crm2\"]\n",
    "\n",
    "experiments_filename = \"experiments_write_predictions_lstm.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in datasets:\n",
    "    if \"github\" in dataset_name or \"crm2\" in dataset_name:\n",
    "        memory = 50000\n",
    "    elif \"hospital_billing\" in dataset_name or \"bpic2017\" in dataset_name:\n",
    "        memory = 30000\n",
    "    elif \"traffic\" in dataset_name or \"bpic2012\" in dataset_name:\n",
    "        memory = 20000\n",
    "    else:\n",
    "        memory = 10000\n",
    "        \n",
    "    for method_name in method_names:\n",
    "        for cls_method in cls_methods:\n",
    "            params = \" \".join([dataset_name, method_name, cls_method])\n",
    "            script_file = \"script_files_lstm/run_writepreds_%s_%s_%s.sh\" % (dataset_name, method_name, cls_method)\n",
    "            with open(script_file, \"w\") as fout:\n",
    "                fout.write(\"#!/bin/bash\\n\")\n",
    "                fout.write(\"#SBATCH --partition=gpu\\n\")\n",
    "                fout.write(\"#SBATCH --gres=gpu:1\\n\")\n",
    "                fout.write(\"#SBATCH --output=output_files/output_%s_%s_%s.txt\\n\" % (dataset_name, method_name,\n",
    "                                                                           cls_method))\n",
    "                fout.write(\"#SBATCH --mem=%s\\n\" % memory)\n",
    "                fout.write(\"#SBATCH --time=7-00\\n\")\n",
    "                fout.write(\"python %s %s\" % (experiments_filename, params))\n",
    "\n",
    "            #time.sleep(1)\n",
    "            #subprocess.Popen((\"sbatch %s\" % script_file).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing predictions (alarms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_names = [\"single_agg\"]\n",
    "cls_methods = [\"xgboost\"]\n",
    "datasets = [\"bpic2011\", \"bpic2015\", \"insurance\", \"sepsis_cases\", \"production\", \"bpic2012_accepted\", \"bpic2012_declined\", \n",
    "           \"bpic2012_cancelled\", \"traffic_fines_1\", \"bpic2017_accepted\", \"bpic2017_refused\", \"bpic2017_cancelled\",\n",
    "           \"hospital_billing_2\", \"hospital_billing_3\"]\n",
    "datasets = [\"sepsis_cases\"]\n",
    "datasets = [\"unemployment\"]\n",
    "datasets = [\"dc\", \"github\", \"crm2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script_files/run_writepreds_dc_single_agg_xgboost.sh\n",
      "script_files/run_writepreds_github_single_agg_xgboost.sh\n",
      "script_files/run_writepreds_crm2_single_agg_xgboost.sh\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in datasets:\n",
    "    if dataset_name in [\"dc\", \"github\", \"crm2\"]:\n",
    "        experiments_filename = \"experiments_write_predictions_alarms_unstructured.py\"\n",
    "    else:\n",
    "        experiments_filename = \"experiments_write_predictions_alarms.py\"\n",
    "    \n",
    "    if dataset_name in [\"dc\", \"github\", \"crm2\"]:\n",
    "        memory = 50000\n",
    "    elif \"hospital_billing\" in dataset_name or \"bpic2017\" in dataset_name:\n",
    "        memory = 30000\n",
    "    elif \"traffic\" in dataset_name or \"crm2\" in dataset_name:\n",
    "        memory = 20000\n",
    "    else:\n",
    "        memory = 10000\n",
    "        \n",
    "    for cls_method in cls_methods:\n",
    "\n",
    "        for method_name in method_names:\n",
    "            \n",
    "            params = \" \".join([dataset_name, method_name, cls_method])\n",
    "            script_file = \"script_files/run_writepreds_%s_%s_%s.sh\" % (dataset_name, method_name, cls_method)\n",
    "            print(script_file)\n",
    "            with open(script_file, \"w\") as fout:\n",
    "                fout.write(\"#!/bin/bash\\n\")\n",
    "                fout.write(\"#SBATCH --output=output_files/output_writepreds_%s_%s_%s.txt\\n\" % (dataset_name, method_name,\n",
    "                                                                           cls_method))\n",
    "                fout.write(\"#SBATCH --mem=%s\\n\" % memory)\n",
    "                fout.write(\"#SBATCH --ntasks=4\\n\")\n",
    "                fout.write(\"#SBATCH --time=7-00\\n\")\n",
    "\n",
    "                fout.write(\"python %s %s\" % (experiments_filename, params))\n",
    "\n",
    "            time.sleep(1)\n",
    "            subprocess.Popen((\"sbatch %s\" % script_file).split())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test results inter-run stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_names = [\"single_agg\"]\n",
    "cls_methods = [\"rf_calibrated\"]\n",
    "datasets = [\"sepsis_cases\", \"production\", \"bpic2012_accepted\", \"bpic2012_declined\", \n",
    "           \"bpic2012_cancelled\"]\n",
    "datasets = [\"bpic2017_accepted\", \"bpic2017_refused\", \"bpic2017_cancelled\"]\n",
    "datasets = [\"bpic2011_f2\", \"bpic2011_f3\", \"bpic2015_4_f2\", \"bpic2015_5_f2\",\n",
    "            \"insurance_activity\"]\n",
    "datasets = [\"hospital_billing_2\", \"hospital_billing_3\"]\n",
    "\n",
    "alpha = 1\n",
    "beta = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script_files/run_interrun_hospital_billing_2_single_agg_rf_calibrated_1_5.sh\n",
      "script_files/run_interrun_hospital_billing_3_single_agg_rf_calibrated_1_5.sh\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in datasets:\n",
    "    if dataset_name in [\"dc\", \"github\", \"crm2\"]:\n",
    "        experiments_filename = \"experiments_test_interrun_stability_unstructured.py\"\n",
    "    else:\n",
    "        experiments_filename = \"experiments_test_interrun_stability.py\"\n",
    "    \n",
    "    if dataset_name in [\"github\", \"crm2\"]:\n",
    "        memory = 50000\n",
    "    elif \"hospital_billing\" in dataset_name or \"bpic2017\" in dataset_name or dataset_name == \"dc\":\n",
    "        memory = 30000\n",
    "    elif \"traffic\" in dataset_name or \"crm2\" in dataset_name:\n",
    "        memory = 20000\n",
    "    else:\n",
    "        memory = 10000\n",
    "        \n",
    "    for cls_method in cls_methods:\n",
    "\n",
    "        for method_name in method_names:\n",
    "            \n",
    "            params = \" \".join([dataset_name, method_name, cls_method, str(alpha), str(beta)])\n",
    "            script_file = \"script_files/run_interrun_%s_%s_%s_%s_%s.sh\" % (dataset_name, method_name, cls_method, alpha, beta)\n",
    "            print(script_file)\n",
    "            with open(script_file, \"w\") as fout:\n",
    "                fout.write(\"#!/bin/bash\\n\")\n",
    "                fout.write(\"#SBATCH --output=output_files/output_interrun_%s_%s_%s_%s_%s.txt\\n\" % (dataset_name, method_name,\n",
    "                                                                           cls_method, alpha, beta))\n",
    "                fout.write(\"#SBATCH --mem=%s\\n\" % memory)\n",
    "                fout.write(\"#SBATCH --ntasks=4\\n\")\n",
    "                fout.write(\"#SBATCH --time=7-00\\n\")\n",
    "\n",
    "                fout.write(\"python %s %s\" % (experiments_filename, params))\n",
    "\n",
    "            time.sleep(1)\n",
    "            subprocess.Popen((\"sbatch %s\" % script_file).split())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize alarm threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_names = [\"single_agg\"]\n",
    "cls_methods = [\"xgboost\"]\n",
    "datasets = [\"insurance_activity\", \"insurance_followup\", \"sepsis_cases_1\", \"sepsis_cases_2\", \"sepsis_cases_4\",\n",
    "            \"production\", \"bpic2012_accepted\", \"bpic2012_declined\", \"bpic2012_cancelled\", \"bpic2011_f1\", \n",
    "            \"bpic2011_f2\", \"bpic2011_f3\", \"bpic2011_f4\", \"bpic2015_1_f2\", \"bpic2015_2_f2\",\n",
    "           \"bpic2015_3_f2\", \"bpic2015_4_f2\", \"bpic2015_5_f2\", \"bpic2017_cancelled\", \"bpic2017_refused\", \n",
    "            \"bpic2017_accepted\", \"traffic_fines_1\", \"hospital_billing_2\", \"hospital_billing_3\"]\n",
    "datasets = [\"insurance_followup\", \"bpic2012_declined\"]\n",
    "datasets = [\"crm2\"]\n",
    "\n",
    "#experiments_filename = \"experiments_optimize_alarm_threshold.py\"\n",
    "#experiments_filename = \"experiments_optimize_alarm_threshold_ccom.py\"\n",
    "experiments_filename = \"experiments_optimize_alarm_threshold_eff.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script_files/run_optthresh_crm2_single_agg_xgboost.sh\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in datasets:\n",
    "    memory = 10000\n",
    "        \n",
    "    for cls_method in cls_methods:\n",
    "\n",
    "        for method_name in method_names:\n",
    "            \n",
    "            params = \" \".join([dataset_name, method_name, cls_method])\n",
    "            script_file = \"script_files/run_optthresh_%s_%s_%s.sh\" % (dataset_name, method_name, cls_method)\n",
    "            print(script_file)\n",
    "            with open(script_file, \"w\") as fout:\n",
    "                fout.write(\"#!/bin/bash\\n\")\n",
    "                fout.write(\"#SBATCH --output=output_files/output_optthresh_%s_%s_%s.txt\\n\" % (dataset_name, method_name,\n",
    "                                                                           cls_method))\n",
    "                fout.write(\"#SBATCH --mem=%s\\n\" % memory)\n",
    "                fout.write(\"#SBATCH --ntasks=1\\n\")\n",
    "                fout.write(\"#SBATCH --time=7-00\\n\")\n",
    "\n",
    "                fout.write(\"python %s %s\" % (experiments_filename, params))\n",
    "\n",
    "            time.sleep(1)\n",
    "            subprocess.Popen((\"sbatch %s\" % script_file).split())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test alarm thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_names = [\"single_agg\"]\n",
    "cls_methods = [\"xgboost\"]\n",
    "datasets = [\"insurance_activity\", \"insurance_followup\", \"sepsis_cases_1\", \"sepsis_cases_2\", \"sepsis_cases_4\",\n",
    "            \"production\", \"bpic2012_accepted\", \"bpic2012_declined\", \"bpic2012_cancelled\", \"bpic2011_f1\", \n",
    "            \"bpic2011_f2\", \"bpic2011_f3\", \"bpic2011_f4\", \"bpic2015_1_f2\", \"bpic2015_2_f2\",\n",
    "           \"bpic2015_3_f2\", \"bpic2015_4_f2\", \"bpic2015_5_f2\", \"bpic2017_cancelled\", \"bpic2017_refused\", \n",
    "            \"bpic2017_accepted\", \"traffic_fines_1\", \"hospital_billing_2\", \"hospital_billing_3\",\n",
    "            \"github\", \"dc\", \"crm2\"]\n",
    "\n",
    "#experiments_filename = \"experiments_test_optimal_alarm_threshold_eff.py\"\n",
    "experiments_filename = \"experiments_test_optimal_alarm_threshold_ccom.py\"\n",
    "#experiments_filename = \"experiments_test_optimal_alarm_threshold.py\"\n",
    "#experiments_filename = \"experiments_test_fixed_alarm_thresholds.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script_files/run_testalarm_insurance_activity_single_agg_xgboost.sh\n",
      "script_files/run_testalarm_insurance_followup_single_agg_xgboost.sh\n",
      "script_files/run_testalarm_sepsis_cases_1_single_agg_xgboost.sh\n",
      "script_files/run_testalarm_sepsis_cases_2_single_agg_xgboost.sh\n",
      "script_files/run_testalarm_sepsis_cases_4_single_agg_xgboost.sh\n",
      "script_files/run_testalarm_production_single_agg_xgboost.sh\n",
      "script_files/run_testalarm_bpic2012_accepted_single_agg_xgboost.sh\n",
      "script_files/run_testalarm_bpic2012_declined_single_agg_xgboost.sh\n",
      "script_files/run_testalarm_bpic2012_cancelled_single_agg_xgboost.sh\n",
      "script_files/run_testalarm_bpic2011_f1_single_agg_xgboost.sh\n",
      "script_files/run_testalarm_bpic2011_f2_single_agg_xgboost.sh\n",
      "script_files/run_testalarm_bpic2011_f3_single_agg_xgboost.sh\n",
      "script_files/run_testalarm_bpic2011_f4_single_agg_xgboost.sh\n",
      "script_files/run_testalarm_bpic2015_1_f2_single_agg_xgboost.sh\n",
      "script_files/run_testalarm_bpic2015_2_f2_single_agg_xgboost.sh\n",
      "script_files/run_testalarm_bpic2015_3_f2_single_agg_xgboost.sh\n",
      "script_files/run_testalarm_bpic2015_4_f2_single_agg_xgboost.sh\n",
      "script_files/run_testalarm_bpic2015_5_f2_single_agg_xgboost.sh\n",
      "script_files/run_testalarm_bpic2017_cancelled_single_agg_xgboost.sh\n",
      "script_files/run_testalarm_bpic2017_refused_single_agg_xgboost.sh\n",
      "script_files/run_testalarm_bpic2017_accepted_single_agg_xgboost.sh\n",
      "script_files/run_testalarm_traffic_fines_1_single_agg_xgboost.sh\n",
      "script_files/run_testalarm_hospital_billing_2_single_agg_xgboost.sh\n",
      "script_files/run_testalarm_hospital_billing_3_single_agg_xgboost.sh\n",
      "script_files/run_testalarm_github_single_agg_xgboost.sh\n",
      "script_files/run_testalarm_dc_single_agg_xgboost.sh\n",
      "script_files/run_testalarm_crm2_single_agg_xgboost.sh\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in datasets:\n",
    "    memory = 10000\n",
    "        \n",
    "    for cls_method in cls_methods:\n",
    "\n",
    "        for method_name in method_names:\n",
    "            \n",
    "            params = \" \".join([dataset_name, method_name, cls_method])\n",
    "            script_file = \"script_files/run_testalarm_%s_%s_%s.sh\" % (dataset_name, method_name, cls_method)\n",
    "            print(script_file)\n",
    "            with open(script_file, \"w\") as fout:\n",
    "                fout.write(\"#!/bin/bash\\n\")\n",
    "                fout.write(\"#SBATCH --output=output_files/output_testalarm_%s_%s_%s.txt\\n\" % (dataset_name, method_name,\n",
    "                                                                           cls_method))\n",
    "                fout.write(\"#SBATCH --mem=%s\\n\" % memory)\n",
    "                fout.write(\"#SBATCH --ntasks=1\\n\")\n",
    "                fout.write(\"#SBATCH --time=7-00\\n\")\n",
    "\n",
    "                fout.write(\"python %s %s\" % (experiments_filename, params))\n",
    "\n",
    "            time.sleep(1)\n",
    "            subprocess.Popen((\"sbatch %s\" % script_file).split())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_names = [\"single_agg\"]\n",
    "cls_methods = [\"rf\", \"xgboost\"]\n",
    "datasets = [\"crm2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in datasets:\n",
    "    if dataset_name == \"crm2\":\n",
    "        memory = 50000\n",
    "    elif \"hospital_billing\" in dataset_name or \"bpic2017\" in dataset_name or dataset_name == \"github\":\n",
    "        memory = 30000\n",
    "    elif \"traffic\" in dataset_name:\n",
    "        memory = 20000\n",
    "    else:\n",
    "        memory = 10000\n",
    "        \n",
    "    for method_name in method_names:\n",
    "        for cls_method in cls_methods:\n",
    "            \n",
    "            script_file = \"script_files/run_training_stability_%s_%s_%s.sh\" % (dataset_name, method_name, cls_method)\n",
    "            with open(script_file, \"w\") as fout:\n",
    "                fout.write(\"#!/bin/bash\\n\")\n",
    "                fout.write(\"#SBATCH --output=output_files_training_stability/output_%s_%s_%s.txt\\n\" % (dataset_name, method_name,\n",
    "                                                                           cls_method))\n",
    "                fout.write(\"#SBATCH --ntasks=8\\n\")\n",
    "                fout.write(\"#SBATCH --mem=%s\\n\" % memory)\n",
    "                fout.write(\"#SBATCH --time=7-00\\n\")\n",
    "\n",
    "                fout.write(\"python experiments_training_stability.py %s %s %s\" % (dataset_name, method_name, cls_method))\n",
    "\n",
    "            time.sleep(1)\n",
    "            subprocess.Popen((\"sbatch %s\" % script_file).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importances (with unstructured data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_names = [\"single_laststate\"]\n",
    "text_method_encs = [\"bong\"]\n",
    "datasets = [\"dc\", \"crm2\"]\n",
    "cls_methods = [\"rf\"]\n",
    "\n",
    "experiments_filename = \"experiments_with_unstructured_data_feature_importance.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script_files/run_feature_imp_dc_single_laststate_bong_rf.sh\n",
      "script_files/run_feature_imp_crm2_single_laststate_bong_rf.sh\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in datasets:\n",
    "    if \"github\" in dataset_name or \"crm2\" in dataset_name:\n",
    "        memory = 50000\n",
    "    else:\n",
    "        memory = 25000\n",
    "        \n",
    "    for cls_method in cls_methods:\n",
    "\n",
    "        for method_name in method_names:\n",
    "            \n",
    "            for text_method in text_method_encs:\n",
    "            \n",
    "                params = \" \".join([dataset_name, method_name, text_method, cls_method])\n",
    "                script_file = \"script_files/run_feature_imp_%s_%s_%s_%s.sh\" % (dataset_name, method_name, text_method, cls_method)\n",
    "                print(script_file)\n",
    "                with open(script_file, \"w\") as fout:\n",
    "                    fout.write(\"#!/bin/bash\\n\")\n",
    "                    fout.write(\"#SBATCH --output=output_files/output_feature_imp_%s_%s_%s_%s.txt\\n\" % (dataset_name, method_name,\n",
    "                                                                               text_method, cls_method))\n",
    "                    fout.write(\"#SBATCH --mem=%s\\n\" % memory)\n",
    "                    fout.write(\"#SBATCH --ntasks=4\\n\")\n",
    "                    fout.write(\"#SBATCH --time=7-00\\n\")\n",
    "\n",
    "                    fout.write(\"python %s %s\" % (experiments_filename, params))\n",
    "\n",
    "                time.sleep(1)\n",
    "                subprocess.Popen((\"sbatch %s\" % script_file).split())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance (unstructured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_names = [\"single_agg\"]\n",
    "text_method_encs = [\"nb\"]\n",
    "datasets = [\"crm2\"]\n",
    "cls_methods = [\"rf\"]\n",
    "n_iter = 1\n",
    "\n",
    "experiments_filename = \"experiments_performance_with_unstructured_data.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script_files/run_performance_crm2_single_agg_nb_rf.sh\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in datasets:\n",
    "    if \"github\" in dataset_name or \"crm2\" in dataset_name:\n",
    "        memory = 50000\n",
    "    else:\n",
    "        memory = 25000\n",
    "        \n",
    "    for cls_method in cls_methods:\n",
    "\n",
    "        for method_name in method_names:\n",
    "            \n",
    "            for text_method in text_method_encs:\n",
    "            \n",
    "                params = \" \".join([dataset_name, method_name, text_method, cls_method, str(n_iter)])\n",
    "                script_file = \"script_files/run_performance_%s_%s_%s_%s.sh\" % (dataset_name, method_name, text_method, cls_method)\n",
    "                print(script_file)\n",
    "                with open(script_file, \"w\") as fout:\n",
    "                    fout.write(\"#!/bin/bash\\n\")\n",
    "                    fout.write(\"#SBATCH --output=output_files/output_performance_%s_%s_%s_%s.txt\\n\" % (dataset_name, method_name,\n",
    "                                                                               text_method, cls_method))\n",
    "                    fout.write(\"#SBATCH --mem=%s\\n\" % memory)\n",
    "                    fout.write(\"#SBATCH --ntasks=1\\n\")\n",
    "                    fout.write(\"#SBATCH --time=7-00\\n\")\n",
    "\n",
    "                    fout.write(\"python %s %s\" % (experiments_filename, params))\n",
    "\n",
    "                time.sleep(1)\n",
    "                subprocess.Popen((\"sbatch %s\" % script_file).split())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_names = [\"prefix_index\"]\n",
    "datasets = [\"crm2\"]\n",
    "cls_methods = [\"rf\", \"xgboost\", \"logit\"]\n",
    "n_iter = 1\n",
    "\n",
    "experiments_filename = \"experiments_performance.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script_files/run_performance_crm2_prefix_index_rf.sh\n",
      "script_files/run_performance_crm2_prefix_index_xgboost.sh\n",
      "script_files/run_performance_crm2_prefix_index_logit.sh\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in datasets:\n",
    "    if \"github\" in dataset_name or \"crm2\" in dataset_name:\n",
    "        memory = 50000\n",
    "    else:\n",
    "        memory = 25000\n",
    "        \n",
    "    for cls_method in cls_methods:\n",
    "\n",
    "        for method_name in method_names:\n",
    "            \n",
    "            params = \" \".join([dataset_name, method_name, cls_method, str(n_iter)])\n",
    "            script_file = \"script_files/run_performance_%s_%s_%s.sh\" % (dataset_name, method_name, cls_method)\n",
    "            print(script_file)\n",
    "            with open(script_file, \"w\") as fout:\n",
    "                fout.write(\"#!/bin/bash\\n\")\n",
    "                fout.write(\"#SBATCH --output=output_files/output_performance_%s_%s_%s.txt\\n\" % (dataset_name, method_name,\n",
    "                                                                           cls_method))\n",
    "                fout.write(\"#SBATCH --mem=%s\\n\" % memory)\n",
    "                fout.write(\"#SBATCH --ntasks=1\\n\")\n",
    "                fout.write(\"#SBATCH --time=7-00\\n\")\n",
    "\n",
    "                fout.write(\"python %s %s\" % (experiments_filename, params))\n",
    "\n",
    "            time.sleep(1)\n",
    "            subprocess.Popen((\"sbatch %s\" % script_file).split())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
